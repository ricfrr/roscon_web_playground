<h1 id="programa-roscon-es-">Programa ROSCon ES *</h1>

<h2 id="workshopstutoriales---19-de-septiembre-de-2024">Workshops/Tutoriales - 19 de septiembre de 2024</h2>

<div class="schedule_3tracks" aria-labelledby="schedule-heading">
	<span class="track-slot" aria-hidden="true" style="grid-column: track-1; grid-row: tracks;">Ed. 45, Planta 1, Aula 05</span>
	<span class="track-slot" aria-hidden="true" style="grid-column: track-2; grid-row: tracks;">Ed. 45, Planta 1, Aula 06</span>
	<span class="track-slot" aria-hidden="true" style="grid-column: track-3; grid-row: tracks;">Ed. 45, Planta 1, Aula 07</span>
	<h3 class="time-slot" style="grid-row: time-0830;">08:30</h3>

	<div class="session session-1 track-all" style="grid-column: track-1-start / track-3-end; grid-row: time-0830 / time-0930;">
		<span class="session-time">08:30 - 09:30</span>
		<span class="session-track">Ed. 45</span>
		<br />
		<h4 class="session-title">Registro</h4>
	</div>

	<h3 class="time-slot" style="grid-row: time-0930;">09:30</h3>

	<div class="session session-2 track-3" style="grid-column: track-3; grid-row: time-0930 / time-1130;">
		<span class="session-time">09:30 - 11:30</span>
		<span class="session-track">Ed. 45, Planta 1, Aula 07</span>
		<br />
		<h4 class="session-title">Tutorial de Gazebo e integración con ros2_control</h4>
		<h4 class="session-presenter">
				Jonathan Cacace (Eurecat)
		</h4>
<p>El objetivo de este tutorial es ayudar a los desarrolladores a tomar sus primeros pasos en el uso de Gazebo, detallando su instalación, configuración e interfaz con ROS 2 empleando bridges correctamente. También se discutirá e implementará la integración profunda con el paquete ros2_control, así como la simulación de diferentes controladores.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1030;">10:30</h3>

	<div class="session session-3 track-2" style="grid-column: track-2; grid-row: time-1030 / time-1130;">
		<span class="session-time">10:30 - 11:30</span>
		<span class="session-track">Ed. 45, Planta 1, Aula 06</span>
		<br />
		<h4 class="session-title">Saca el máximo partido a Foxglove empleando tus propios datos</h4>
		<h4 class="session-presenter">
				José Luis Millán Valbuena (Foxglove Technologies Inc.)
		</h4>
<p>Acelera tu desarrollo en robótica aprovechando todo el potencial de Foxglove, un software de visualización de primera clase, empleando tus propios datos. En este taller, trabajaremos con rosbags compartidos por ti y la comunidad para mostrar casos de uso reales donde aprenderemos cómo Foxglove puede aumentar tu productividad y la de tu equipo.</p>
<p>¡Y además, es gratis!</p>
<p><a href="mailto:foxgloverosconesp@gmail.com" style="color:white;font-weight:bold" class="video-link">✉️ ¡Mándanos tu rosbag aquí!</a></p>
<p><a href="https://docs.google.com/presentation/d/1Xo1kyP4qv-_DmnRBAlSppKNiKdl4LxxlJzA3pUUj5fc/edit" style="color:white;font-weight:bold" class="video-link">🌐 Presentación</a></p>
<p><a href="https://github.com/foxglove/tutorials" style="color:white;font-weight:bold" class="video-link">🤖 Material del workshop</a></p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1130;">11:30</h3>

	<div class="session session-4 track-1" style="grid-column: track-1; grid-row: time-1130 / time-1330;">
		<span class="session-time">11:30 - 13:30</span>
		<span class="session-track">Ed. 45, Planta 1, Aula 05</span>
		<br />
		<h4 class="session-title">Desarrollo de Aplicaciones Reales en Robótica con ROS 2 y Rust</h4>
		<h4 class="session-presenter">
				Júlia Marsal Perendreu (JMRobotics)
		</h4>
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>En este taller, los participantes explorarán el desarrollo de aplicaciones robóticas reales utilizando el lenguaje de programación Rust, enfocándose en una plataforma de robot cuadrúpedo. La sesión cubrirá los fundamentos de Rust, sus ventajas en robótica y técnicas de implementación prácticas. Los asistentes aprenderán cómo aprovechar las características de rendimiento y seguridad de Rust para construir sistemas robóticos robustos y eficientes. A través de actividades prácticas, adquirirán experiencia en la programación y control de un robot cuadrúpedo, comprendiendo las complejidades de las aplicaciones robóticas reales. Este taller es ideal para quienes desean avanzar en sus habilidades robóticas con un lenguaje de programación moderno y potente.</p>
		</details>
		<p><a href="https://github.com/roboticswithjulia/ros2_rust_workshop/blob/main/README.md" style="color:white;font-weight:bold" class="video-link">🤖 Requisitos del workshop</a></p>
		<p><a href="https://github.com/roboticswithjulia/ros2_rust_workshop" style="color:white;font-weight:bold" class="video-link">🌐 Documentación del workshop</a></p>
	</div>

	<div class="session session-5 track-2" style="grid-column: track-2; grid-row: time-1130 / time-1330;">
		<span class="session-time">11:30 - 13:30</span>
		<span class="session-track">Ed. 45, Planta 1, Aula 06</span>
		<br />
		<h4 class="session-title">ROS + Docker = Robótica Reproducible</h4>
		<h4 class="session-presenter">
				Enric Cervera Mateu (Universitat Jaume I de Castelló)
		</h4>
<p>El objetivo principal de este tutorial es aprender a usar contenedores Docker para manejar cualquier distribución de ROS independientemente del sistema operativo instalado en la máquina. Además, se mostrará cómo gestionar las dependencias del software para simplificar la instalación y el funcionamiento de los paquetes de ROS. El tutorial abordará diferentes casos prácticos tanto en simulación 2D/3D (incluyendo el uso de GPUs) como con robots y dispositivos reales. El resultado final serán paquetes de software de ROS reproducibles en cualquier máquina con el mínimo esfuerzo.</p>
	</div>

	<div class="session session-6 track-3" style="grid-column: track-3; grid-row: time-1130 / time-1330;">
		<span class="session-time">11:30 - 13:30</span>
		<span class="session-track">Ed. 45, Planta 1, Aula 07</span>
		<br />
		<h4 class="session-title">Orquestación de comportamientos complejos con Behavior Trees</h4>
		<h4 class="session-presenter">
				Magí Dalmau Moreno (Eurecat)<br />
				Devis Dal Moro (Eurecat)
		</h4>
<p>Este workshop está dedicado a divulgar bases metodológicas para la orquestación de comportamientos complejos basados en Behavior Trees en conjunción con otras herramientas. Las ponencias cubrirán desde los aspectos fundamentales a metodologías avanzadas. Además, se explicarán buenas prácticas en dominios concretos, como puede ser la orquestación del razonamiento, de la interacción hombre-robot, de la manipulación de objetos y de la navegación en entornos complejos.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1330;">13:30</h3>

	<div class="session session-7 track-all" style="grid-column: track-1-start / track-3-end; grid-row: time-1330 / time-1500;">
		<span class="session-time">13:30 - 15:00</span>
		<span class="session-track">Ed. 45</span>
		<br />
		<h4 class="session-title">Comida</h4>
	</div>

	<h3 class="time-slot" style="grid-row: time-1500;">15:00</h3>

	<div class="session session-8 track-1" style="grid-column: track-1; grid-row: time-1500 / time-1700;">
		<span class="session-time">15:00 - 17:00</span>
		<span class="session-track">Ed. 45, Planta 1, Aula 05</span>
		<br />
		<h4 class="session-title">Aerostack2, desarrolla tu enjambre de drones desde simulación a real</h4>
		<h4 class="session-presenter">
				Rafael Pérez Seguí (Universidad Politécnica de Madrid)<br />
				Pedro Arias Pérez (Universidad Politécnica de Madrid)
		</h4>
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Este taller se centrará en el manejo de enjambres robóticos aéreos, con un tutorial sobre Aerostack2, un framework de código abierto basado en ROS 2, que ofrece una solución integral y flexible para el diseño e implementación de sistemas autónomos de robots aéreos. El objetivo es ayudar a los asistentes a diseñar y validar sus propios sistemas robóticos mediante un tutorial en el que se mostrará el proceso de diseño y la transición de simulación a la aplicación real haciendo uso de esta herramienta. Para ello, en el taller se hará uso del simulador Gazebo y de los drones reales Crazyflies.</p>
		</details>
<p><a href="https://github.com/aerostack2/demo_ROSConES24" style="color:white;font-weight:bold" class="video-link">🤖 Material del workshop</a></p>
	</div>

	<div class="session session-9 track-2" style="grid-column: track-2; grid-row: time-1500 / time-1700;">
		<span class="session-time">15:00 - 17:00</span>
		<span class="session-track">Ed. 45, Planta 1, Aula 06</span>
		<br />
		<h4 class="session-title">Tutorial de TIAGo en ROS 2</h4>
		<h4 class="session-presenter">
				Noel Jiménez García (PAL Robotics)
		</h4>
<p>Este taller es una experiencia práctica con la simulación del robot TIAGo. Los participantes podrán ejecutar ejercicios en un entorno simulado, que luego serán transferidos y probados en el robot real.</p>
	</div>

	<div class="session session-10 track-3" style="grid-column: track-3; grid-row: time-1500 / time-1900;">
		<span class="session-time">15:00 - 19:00</span>
		<span class="session-track">Ed. 45, Planta 1, Aula 07</span>
		<br />
		<h4 class="session-title">Programación en Tiempo Real en ROS 2</h4>
		<h4 class="session-presenter">
				Francisco Martín Rico (Universidad Rey Juan Carlos)
		</h4>
<p>Este workshop aborda los principios de la programación de aplicaciones en Tiempo Real, introduciendo inicialmente los principios técnicos, luego la programación de aplicaciones generales, y posteriormente técnicas de tiempo real en ROS 2.</p>
<p><a href="https://github.com/fmrico/roscon-es-2024-realtime-workshop" style="color:white;font-weight:bold" class="video-link">🤖 Material y requisitos del workshop</a></p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1700;">17:00</h3>

	<div class="session session-11 track-1" style="grid-column: track-1; grid-row: time-1700 / time-1900;">
		<span class="session-time">17:00 - 19:00</span>
		<span class="session-track">Ed. 45, Planta 1, Aula 05</span>
		<br />
		<h4 class="session-title">Simulación de manipuladores y sistema de visión en Isaac Sim con ROS 2</h4>
		<h4 class="session-presenter">
				Mohamed Khalil Kahlaoui (Universidad Politécnica de Madrid )
		</h4>
<p>Este workshop aborda la simulación de manipuladores UR, tanto para configuración individual como multi-robot, y su integración con sistemas de visión por cámara utilizando Nvidia Isaac Sim y ROS 2. Se explicará el uso de diferentes planificadores de trayectorias disponibles en el entorno de Isaac sim como LULA RMPFlow, y Curobo, y cómo emplear ROS para una integración completa de estas herramientas.</p>
<p><a href="https://github.com/DarK404/Manipulators-simulation-workshop-roscon-es-2024" style="color:white;font-weight:bold" class="video-link">🤖 Material del workshop</a></p>
	</div>

	<div class="session session-12 track-2" style="grid-column: track-2; grid-row: time-1700 / time-1900;">
		<span class="session-time">17:00 - 19:00</span>
		<span class="session-track">Ed. 45, Planta 1, Aula 06</span>
		<br />
		<h4 class="session-title">HRI con el TIAGo Pro vía ROS4HRI</h4>
		<h4 class="session-presenter">
				Óscar Martínez (PAL Robotics)
		</h4>
<p>En este workshop introduciremos el robot TIAGo Pro, el nuevo manipulador móvil de PAL Robotics, con aplicación directa del standard ROS4HRI integrado en él.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1900;">19:00</h3>

	<div class="session session-13 track-all" style="grid-column: track-1-start / track-3-end; grid-row: time-1900 / time-2130;">
		<span class="session-time">19:00 - 21:30</span>
		<span class="session-track">Ed. 45</span>
		<br />
		<h4 class="session-title">Welcome Reception</h4>
	</div>

</div>
<h2 id="charlas-técnicas---20-de-septiembre-de-2024">Charlas Técnicas - 20 de septiembre de 2024</h2>

<div class="schedule_2tracks" aria-labelledby="schedule-heading">
	<span class="track-slot" aria-hidden="true" style="grid-column: track-1; grid-row: tracks;">Paraninfo</span>
	<span class="track-slot" aria-hidden="true" style="grid-column: track-2; grid-row: tracks;">Sala de Grados, Ed. 7</span>
	<h3 class="time-slot" style="grid-row: time-0830;">08:30</h3>

	<div class="session session-1 track-all" style="grid-column: track-1-start / track-2-end; grid-row: time-0830 / time-0900;">
		<span class="session-time">08:30 - 09:00</span>
		<span class="session-track">Paraninfo</span>
		<br />
		<h4 class="session-title">Registro</h4>
	</div>

	<h3 class="time-slot" style="grid-row: time-0900;">09:00</h3>

	<div class="session session-2 track-all" style="grid-column: track-1-start / track-2-end; grid-row: time-0900 / time-0915;">
		<span class="session-time">09:00 - 09:15</span>
		<span class="session-track">Paraninfo</span>
		<br />
		<h4 class="session-title">Bienvenida</h4>
	</div>

	<h3 class="time-slot" style="grid-row: time-0915;">09:15</h3>

	<div class="session session-3 track-1" style="grid-column: track-1; grid-row: time-0915 / time-0945;">
		<span class="session-time">09:15 - 09:45</span>
		<span class="session-track">Paraninfo<br />Desarrollo y Despliegue en ROS</span>
		<br />
		<h4 class="session-title">Estado de ROS Jazzy y Gazebo Harmonic</h4>
		<h4 class="session-presenter">
				Alejandro Hernández Cordero (Consultor de robótica independiente)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493286" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>ROS y Gazebo son un proyectos complejos con muchas partes móviles. Es difícil para cualquier persona entender todo lo que está pasando y hacia dónde va. En esta charla, se brindarán una descripción general de las nuevas características técnicas de Jazzy Jalisco y Gazebo Harmonic, lo que se está planeando para Kilted y en qué objetivos a largo plazo está trabajando actualmente el proyecto.</p>
	</div>

	<div class="session session-4 track-2" style="grid-column: track-2; grid-row: time-0915 / time-0930;">
		<span class="session-time">09:15 - 09:30</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />Navegación</span>
		<br />
		<h4 class="session-title">Navegación robusta en ROS 2</h4>
		<h4 class="session-presenter">
				José Carlos García Moreno (PAL Robotics)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492785" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>En esta charla explicaremos los pasos esenciales para configurar y ejecutar navegación robusta en el TIAGo en ROS 2. Analizaremos el estado actual las mejoras de NAV2 en simulación y con robots reales.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-0930;">09:30</h3>

	<div class="session session-5 track-2" style="grid-column: track-2; grid-row: time-0930 / time-0945;">
		<span class="session-time">09:30 - 09:45</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />Navegación</span>
		<br />
		<h4 class="session-title">Desarrollo de un comandante de navegación basado en Nav2 para entornos agrícolas</h4>
		<h4 class="session-presenter">
				Pau Reverté Martínez (Eurecat)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492471" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>En esta charla se presentará un enfoque innovador para el desarrollo de un comandante de alto nivel basado en Nav2 para diferentes métodos de navegación en el entorno agrícola. Basado en la navegación de Nav2 y sus diferentes componentes tales como planificadores, controladores o detectores de colisión, este comandante actuará como un orquestador de cada uno de ellos a través de diferentes modos de navegación utilizando Behavior Trees, adaptados a las especificaciones y necesidades de diferentes escenarios y vehículos agrícolas.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-0945;">09:45</h3>

	<div class="session session-6 track-1" style="grid-column: track-1; grid-row: time-0945 / time-1000;">
		<span class="session-time">09:45 - 10:00</span>
		<span class="session-track">Paraninfo<br />Desarrollo y Despliegue en ROS</span>
		<br />
		<h4 class="session-title">Cáscade LifeCycle Nodes: Un gran building block para arquitecturas de software de robots eficientes</h4>
		<h4 class="session-presenter">
				Francisco Martín Rico (Universidad Rey Juan Carlos)
		</h4>
		<a href="https://github.com/fmrico/cascade_lifecycle" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029493184" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Las arquitecturas de software dictan la organización del software dentro de un robot. Una arquitectura eficaz facilita la escalabilidad y adaptabilidad del sistema para nuevas tareas al tiempo que gestiona aspectos críticos como la carga computacional y el rendimiento en tiempo real. Esta charla presenta Cascade LifeCycle, un componente fundamental para las arquitecturas de software. Este componente permite la construcción de arquitecturas escalables y eficientes activando elementos en cascada solo cuando sea necesario para lograr los objetivos activos del robot. Esta metodología apoya la creación de arquitecturas de subsunción eficientes o arquitecturas de tres capas, simplificando la tarea del programador al ocultar la complejidad de la coordinación de componentes. Presentamos una implementación en ROS 2 utilizando LifeCycle Nodes y demostramos la efectividad de nuestro enfoque en entornos de competencia robótica y entornos de enseñanza universitaria utilizando robots reales.</p>
		</details>
	</div>

	<div class="session session-7 track-2" style="grid-column: track-2; grid-row: time-0945 / time-1000;">
		<span class="session-time">09:45 - 10:00</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />Navegación</span>
		<br />
		<h4 class="session-title">Navegación multirobot en escenarios con agentes cooperativos y no cooperativos</h4>
		<h4 class="session-presenter">
				Diego Martínez Baselga (Universidad de Zaragoza)
		</h4>
		<a href="https://github.com/dmartinezbaselga/ekf_optitrack" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://arxiv.org/abs/2407.00507" target="_blank" style="color:white" class="video-link">🌐 Leer más</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029492770" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>En esta charla se presenta el planeador AVOCADO, que combina métodos geométricos con una innovadora formulación de control para estimar y adaptar el grado de cooperación del robot durante la navegación en entornos multitudinarios con agentes de cooperación desconocida (personas, robots, etc.) sin comunicación entre ellos. Se discutirán los detalles de la experimentación en un entorno multirobot con hasta seis agentes (robots y personas), utilizando un sistema OptiTrack y un filtro de Kalman para la percepción; en donde ROS desempeñó un papel fundamental en la integración ordenada del sistema y en el lanzamiento coordinado de los experimentos.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1000;">10:00</h3>

	<div class="session session-8 track-all" style="grid-column: track-1-start / track-2-end; grid-row: time-1000 / time-1010;">
		<span class="session-time">10:00 - 10:10</span>
		<br />
		<h4 class="session-title">Shuffle</h4>
	</div>

	<h3 class="time-slot" style="grid-row: time-1010;">10:10</h3>

	<div class="session session-9 track-1" style="grid-column: track-1; grid-row: time-1010 / time-1025;">
		<span class="session-time">10:10 - 10:25</span>
		<span class="session-track">Paraninfo<br />Desarrollo y Despliegue en ROS</span>
		<br />
		<h4 class="session-title">Arquetipos: una metodología y una herramienta para estandarizar y facilitar el diseño de nodos en ROS</h4>
		<h4 class="session-presenter">
				Santiago Tapia Fernández (Universidad Politécnica de Madrid)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493129" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Según instrucciones recibidas por correo electrónico incluyo el resumen corto, pero también el esquema de la charla.</p>
<p>Resumen</p>
<p>Esta charla presenta una forma sistemática de estandarizar el diseño de paquetes y nodos de ROS usando plantillas de Jinja2. Se mostrarán ejemplos de aplicación a casos básicos de nodos que usan temas y otros más complejos que incluyen servicios o plugins. Estos ejemplos utilizan una herramienta que consta de un paquete de ROS2 en python y de un conjunto ampliable de plantillas de Jinja2 con el diseño prototípico (que hemos llamado Arquetipo).</p>
<p>El uso de los Arquetipos que proponemos debería ser útil para la mejora y la estandarización de los diseños de los nodos, para el desarrollo de pruebas automáticas, para hacer análisis a priori de sistemas formados por nodos de ROS2 y para mejorar la modularidad de dichos sistemas.</p>
<p>Objetivos y motivación.</p>
<p>El desarrollo de los Arquetipos como una metodología y una herramienta (un paquete de Python en ROS) se motiva sobre el objetivo general de facilitar y estandarizar el diseño de nodos de ROS sin perder flexibilidad ni adaptabilidad a todo tipo de circunstancias. Además, idealmente, permitiría que una buena parte de los ingenieros de un equipo puedan evitar conocer ROS2 salvo por sus conceptos más generales. Todo ello gracias a que se separa el código fuente asociado a la funcionalidad del asociado a las comunicaciones y las interacciones entre nodos de ROS.</p>
<p>En concreto se consideran los siguientes objetivos concretos:</p>
<ul>
<li>
<p>Estandarizar el diseño de nodos y paquetes de ROS.</p>
</li>
<li>
<p>Proporcionar información sobre las interacciones de un nodo a través de metadatos (equivalente a un IDL).</p>
</li>
<li>
<p>Transformar el diseño en un módulo de software que puede ser modificado y actualizado.</p>
</li>
<li>
<p>Separar el código fuente asociado a la funcionalidad del nodo del código fuente relacionado con sus interacciones y comunicaciones con otros nodos.</p>
</li>
</ul>
<p>Fundamentos y descripción de la metodología.</p>
<p>La metodología de trabajo con Arquetipos se basa en el diseño de un nodo arquetípico, es decir, un nodo representativo de un diseño común y repetido en el trabajo de un equipo. Este nodo se escribe con una funcionalidad trivial para permitir la abstracción sobre los elementos sintácticos necesarios para escribir el nodo de forma generalizada y separando la interacción con otros nodos de la propia funcionalidad. Estos elementos incluyen: clases con sus atributos y métodos, objetos, variables, funciones, callbacks, etc. Por supuesto, este nodo debe ser correcto y estar validado respecto de su funcionalidad y diseño.</p>
<p>A partir de este nodo arquetípico se extraen: los datos necesarios para describir los elementos sintácticos, por ejemplo: atributos necesarios de una clase, su tipo, si se necesita un archivo de cabeceras; la cardinalidad de dichos elementos, etc. En general, se trata de obtener cuál es la representación en forma de metadatos de las interacciones del nodo y los detalles que permite su implementación. Esta información se debe poder expresar en un esquema cuya definición es, en cierta manera, análoga a un IDL (un lenguaje de definición de interfaces), pero que se concreta en archivo YAML para facilitar su manipulación tanto por el usuario como por las herramientas desarrolladas. Se ha denominado a estos archivos como archivos “manifest.yaml”.</p>
<p>En paralelo a la obtención de los metadatos se trabaja en la generación de una plantilla que permita escribir el código de forma automática a partir de esos metadatos. Para la escritura y procesamiento de plantillas se ha elegido Jinja2, una herramienta que permite la generación de archivos de texto a partir de plantillas y que se usa especialmente en el contexto del desarrollo de aplicaciones Web (para generar HTML, pero es absolutamente aplicable a cualquier tipo de formato de archivo incluidos lenguajes de programación como pueden ser C++ o Python. Es más, por su generalidad también se pueden generar archivos XML (como el package.xml), el CMakeLists.txt o los archivos de licencia.</p>
<p>Finalmente se utiliza un script (de Python) para transformar la plantilla y los metadatos en todos los archivos que forman un paquete de ROS2, incluido el código fuente del nodo. Naturalmente en esta sustitución se prevé el lugar que debe ocupar el código fuente asociado a la funcionalidad del nodo y, si la plantilla se diseña de forma correcta, todo este código debe quedar separado en archivos aparte de los generados de forma automática por aplicación de la plantilla.</p>
<p>En resumen, la metodología se basa en los siguientes pasos:</p>
<ul>
<li>
<p>Desarrollo de un nodo arquetípico de funcionalidad trivial.</p>
</li>
<li>
<p>Validación, prueba, comprobación y evaluación del diseño del nodo arquetípico.</p>
</li>
<li>
<p>Análisis del diseño: abstracción del nodo para extraer un esquema de metadatos (el formato de un archivo YAML) y una plantilla de Jinja2 (para cada archivo incluido en el paquete ROS).</p>
</li>
<li>
<p>Desarrollo del script para la sustitución de los metadatos en cada una de las plantillas de los archivos del nodo.</p>
</li>
<li>
<p>Escritura de los archivos “manifest.yaml” para la generación del diseño de los nodos/paquetes de ROS.</p>
</li>
<li>
<p>Ejecución del script y obtención del código fuente del paquete acorde con el diseño previsto en el arquetipo.</p>
</li>
<li>
<p>Escritura del código asociado a la funcionalidad (en archivos aparte).</p>
</li>
</ul>
<p>Una característica importante de la aplicación de esta metodología es que, si se aplica correctamente, se puede reescribir una plantilla y volver a generar los archivos asociados al diseño sin tener que perder o cambiar la funcionalidad del nodo, naturalmente siempre que no cambien las interacciones del nodo. Así, por ejemplo, se podría añadir nueva información de depuración, algún nuevo mecanismo de optimización en el preprocesamiento de los mensajes, cambiar el tipo de nodo (por ejemplo, a nodos gestionados), etc.</p>
<p>A efectos de nomenclatura se va a denominar Arquetipo al par formado por el esquema del archivo “manifest.yaml” y las plantillas Jinja2 de cada uno de los archivos que forman el paquete de un nodo de ROS2.</p>
<p>Herramientas desarrolladas</p>
<p>Se ha aplicado la metodología a una serie de nodos arquetípicos básicos para desarrollar el formato de los archivos manifest, las plantillas de Jinja2 y los scripts de Python que permiten su aplicación a todos los archivos de un paquete de ROS2. Todo ello para proporcionar: una herramienta que se puede usar directamente y, simultáneamente, un ejemplo de aplicación de la metodología para desarrollar arquetipos propios.</p>
<p>Entre los ejemplos se incluye:</p>
<ul>
<li>
<p>Un arquetipo que procesa temas (topics) de ROS2 y usa callbacks de tipo función para el código asociado a la funcionalidad del nodo.</p>
</li>
<li>
<p>Un arquetipo que genera el diseño de un nodo que es:</p>
</li>
<li>
<p>Un gestor de plugins donde la clase del plugin a cargar se define en un parámetro de ROS (y es actualizable),</p>
</li>
<li>
<p>donde cada plugin recibe la llamada una función tick (un temporizador) y, opcionalmente, llamadas a callbacks asociadas a la suscripción a algún tema y</p>
</li>
<li>
<p>un componente (vía registro en el sistema de componentes).</p>
</li>
</ul>
<p>Trabajo futuro.</p>
<p>Aparte de las funcionalidades descritas, en el futuro más inmediato se van a explorar dos aplicaciones que se consideran útiles en el contexto del desarrollo de nodos ROS2:</p>
<p>1) Desarrollo de Arquetipos que incluyan un entorno para la generación de pruebas automáticas del nodo. La idea será generar un nodo “espejo” y suministrar como parte de la plantilla un programa “tester” que sea capaz de ejecutar pruebas especificadas a través de archivos de texto en un formato sencillo. De esta manera el diseño de las pruebas se limitaría a escribir los datos sobre los que trabaja el nodo y el resultado esperado.</p>
<p>2) Un entorno que permita el análisis a nivel de sistema de una arquitectura de nodos. La idea es partir de los archivos “manifest.yaml” para analizar las características del sistema, pero sin necesidad de ejecutar. Este análisis permitiría, por ejemplo, detectar temas sin suscriptores, servicios críticos y, en general, establecer cómo son las interacciones entre los nodos.</p>
<p>Todas las herramientas serán libres y estarán disponibles a través de un repositorio público de GIT.</p>
		</details>
	</div>

	<div class="session session-10 track-2" style="grid-column: track-2; grid-row: time-1010 / time-1030;">
		<span class="session-time">10:10 - 10:30</span>
		<span class="session-track">Sala de Grados, Ed. 7</span>
		<br />
		<h4 class="session-title">Revolucionando el reparto de última milla con una solución de movilidad autónoma y sostenible</h4>
		<h4 class="session-presenter">
				Rafael Uceda Gallegos (GMV y Scoobic)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492923" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Descubre cómo Scoobic y GMV están revolucionando el reparto urbano de última milla utilizando tecnología 5G, IA y un innovador modelo de negocio de pago por uso. A través de una plataforma software integrada para controlar y gestionar los vehículos eléctricos de forma autónoma, optimizamos la eficiencia de los servicios de entrega reduciendo los tiempos e impacto ambiental. Conocerás más detalles sobre el proyecto “Scoobic MED: Vehículo Logístico Eléctrico Autónomo 5G en pago por uso inteligente” y la solución uPathWay que está transformando la logística urbana y el futuro del reparto sostenible.</p>
<p>El Proyecto “Scoobic MED: Vehículo Logístico Eléctrico Autónomo 5G en pago por uso inteligente”, ha sido financiado por el Ministerio para la Transformación Digital y de la Función Pública, mediante el Programa UNICO SECTORIAL 5G 2022 a través del Plan de Recuperación, Transformación y Resiliencia. Este proyecto cuenta con un presupuesto total de 2.950.594 €, de los cuales se han concedido una ayuda de 1.770.356 €. Los beneficiarios principales son Passion Motorbike Factory S.L en cooperación con Scoobic Urban Mobility S.L, con GMV como entidad subcontratada.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1025;">10:25</h3>

	<div class="session session-11 track-1" style="grid-column: track-1; grid-row: time-1025 / time-1035;">
		<span class="session-time">10:25 - 10:35</span>
		<span class="session-track">Paraninfo<br />Desarrollo y Despliegue en ROS</span>
		<br />
		<h4 class="session-title">Cloud native ROS: Desafíos y Soluciones</h4>
		<h4 class="session-presenter">
				Daniel González El Yachouti (Universitat Politécnica de València)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493200" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>En esta charla exploraremos cómo las tecnologías cloud native pueden facilitar la integración y el despliegue de soluciones robóticas basadas en ROS. Se presentarán los principales desafíos en la integración, despliegue y escalabilidad de soluciones de robótica basadas en Inteligencia Artificial y se abordarán los principales beneficios de utilizar tecnologías cloud native (Docker, Helm y Kubernetes) junto con ROS, que facilitan la interoperabilidad, gestión de versiones y escalabiidad o el uso de software abierto, entre otros). También hablaremos de principales retos (complejidad y la curva de aprendizaje) en la adopción de estas tecnologías. Finalmente, presentaremos una estrategia para superar estos retos con un enfoque de Integración Continua y Despliegue Continuo (CI/CD). Nuestra propuesta optimiza el despliegue de soluciones modulares basadas en ROS en el edge, permitiendo una gestión eficiente en entornos distribuidos.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1030;">10:30</h3>

	<div class="session session-12 track-2" style="grid-column: track-2; grid-row: time-1030 / time-1040;">
		<span class="session-time">10:30 - 10:40</span>
		<span class="session-track">Sala de Grados, Ed. 7</span>
		<br />
		<h4 class="session-title">Uso de cámaras hyperespectrales para conducción autónoma de vehículos todoterreno</h4>
		<h4 class="session-presenter">
				Ángel Soriano Vigueras (Robotnik)
		</h4>
		<a href="https://robotnik.eu/wp-content/uploads/2021/06/Robotnik-RB-CAR-Datasheet-210628-ES.pdf" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029493010" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>La charla comenzará describiendo la problemática de la navegación autónoma de vehículos terrestres por terrenos no pavimentados, donde la vegetación y el entorno es muy cambiante y en muchos casos no es posible utilizar las mismas estrategias que en entornos semiestáticos. A continuación se presentarán los beneficios de la integración de sensores hyperespectrales (en ROS) para mejorar la comprensión del entorno y mejorar la navegación autónoma en entornos con vegetación. Y finalmente se expondrá la arquitectura de integración real basada en ROS sobre la que se está trabajando para ofrecer una solución con el vehículo autónomo Rb-car.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1035;">10:35</h3>

	<div class="session session-13 track-1" style="grid-column: track-1; grid-row: time-1035 / time-1045;">
		<span class="session-time">10:35 - 10:45</span>
		<span class="session-track">Paraninfo<br />Desarrollo y Despliegue en ROS</span>
		<br />
		<h4 class="session-title">Organizando el desarrollo de ROS usando Docker</h4>
		<h4 class="session-presenter">
				José Luis Millán Valbuena (SDLE NexGen)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493569" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>Como emplear Docker para gestionar los desarrollos de ROS en tu empresa. Comenzando por las imágenes base para mantener las dependencias bajo control, a compartir imágenes empleando un Docker registry en servidor privado.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1040;">10:40</h3>

	<div class="session session-14 track-2" style="grid-column: track-2; grid-row: time-1040 / time-1055;">
		<span class="session-time">10:40 - 10:55</span>
		<span class="session-track">Sala de Grados, Ed. 7</span>
		<br />
		<h4 class="session-title">Robot Colaborativo en la construcción: implementación y caso de uso, con ROS y MoveIt</h4>
		<h4 class="session-presenter">
				Carlos Gascon Bononad (Robotnik)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492944" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>En esta charla se presentará un caso práctico de un robot móvil manipulador que colabora con operarios en una zona de construcción, facilitando diversas tareas. Se explicará el uso de ROS junto a MoveIt y brazos UR, combinando lo mejor de ambas tecnologías. Además, se detallarán las soluciones implementadas para reducir errores y eliminar colisiones entre la base móvil y el brazo manipulador.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1045;">10:45</h3>

	<div class="session session-15 track-1" style="grid-column: track-1; grid-row: time-1045 / time-1055;">
		<span class="session-time">10:45 - 10:55</span>
		<span class="session-track">Paraninfo</span>
		<br />
		<h4 class="session-title">Interfaz ROS para RL con TIAGo en Isaac</h4>
		<h4 class="session-presenter">
				Alberto San Miguel Tello (Eurecat)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493457" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>En esta charla mostrare una interfaz para poder transferir políticas de Reinforcement Learning obtenidas usando el entorno Isaac de NVIDIA a ROS, usando como ejemplo el robot TIAGo.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1055;">10:55</h3>

	<div class="session session-16 track-all" style="grid-column: track-1-start / track-2-end; grid-row: time-1055 / time-1125;">
		<span class="session-time">10:55 - 11:25</span>
		<span class="session-track">Paraninfo</span>
		<br />
		<h4 class="session-title">Coffee Break</h4>
	</div>

	<h3 class="time-slot" style="grid-row: time-1125;">11:25</h3>

	<div class="session session-17 track-1" style="grid-column: track-1; grid-row: time-1125 / time-1140;">
		<span class="session-time">11:25 - 11:40</span>
		<span class="session-track">Paraninfo<br />Desarrollo y Despliegue en ROS: Diseño Basado en Modelos (MDD)</span>
		<br />
		<h4 class="session-title">Integración sistemática de sistemas robóticos usando tecnologías basadas en modelos (MDD) sobre ROS</h4>
		<h4 class="session-presenter">
				Nadia Hammoudeh García (Fraunhofer IPA)<br />
				Francisco Martín Rico (Universidad Rey Juan Carlos)
		</h4>
		<a href="https://github.com/ipa320/RosTooling" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://ipa320.github.io/RosTooling.github.io/" target="_blank" style="color:white" class="video-link">🌐 Leer más</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029493439" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>ROS (ROS 2) es el ecosistema más popular para el desarrollo de sistemas robóticos. La facilidad y rapidez con la que permite prototipar cualquier aplicación robótica lo han convertido en un estándar sin competencia en el mundo del código abierto. Sin embargo, su naturaleza de código escrito a mano, sin restricciones al desarrollador, junto con la complejidad creciente de los sistemas a integrar, hacen que el proceso de composición y despliegue de sistemas complejos sea una tarea tediosa y que consume mucho tiempo en depuración de errores y pruebas. En otros dominios más consolidados, la tecnología de desarrollo basado en modelos (MDD) ha conseguido optimizar los procesos de integración. La propuesta de RosTooling es combinar las ventajas de ambos mundos, aplicando modelado al código existente de ROS (ROS 2). Para ello, hemos creado una serie de herramientas que permiten extraer modelos a partir del código ya existente o de robots en funcionamiento, y diseñar y validar de la composición de componentes y sistemas. Además MDD permite integrar fácilmente generación automática de código, de documentación o artefactos de despliegue, como paquetes que contienen archivos de configuración y launchers, incluso contenedores de Docker.</p>
<p>La charla estará estructurada en las siguientes secciones: 1) Motivación y visualización del problema, 2) Propuesta e implementación, 3) Aplicabilidad en diferentes escenarios, y 4) Experimentos realizados en robots reales y resultados obtenidos.</p>
<p>Todo el código relacionado con RosTooling es completamente abierto con licencia Apache 2.0 y viene acompañado de una extensa documentación, además de tutoriales y ejemplos de uso. </p>
		</details>
	</div>

	<div class="session session-18 track-2" style="grid-column: track-2; grid-row: time-1125 / time-1140;">
		<span class="session-time">11:25 - 11:40</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />HRI y Robótica Social</span>
		<br />
		<h4 class="session-title">El impacto del tiempo real en los sistemas de percepción activa aplicados a la robótica social</h4>
		<h4 class="session-presenter">
				A. Alberto García Gómez-Jacinto (Universidad Rey Juan Carlos)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492534" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Esta charla examinará la importancia de las capacidades en tiempo real para habilitar que los robots interactúen de manera efectiva en entornos humanos dinámicos, abordando las limitaciones de latencia y computacionales que afectan a los sistemas tradicionales. Se propondrá un enfoque integrado dentro del marco de trabajo ROS 2, aprovechando modelos avanzados de detección de objetos y nodos de ciclo de vida en cascada para garantizar un seguimiento robusto y eficiente de individuos y objetos. Se discutirá cómo la cabeza o cámara del robot debe moverse y dirigirse hacia estímulos visuales. Además, se presentará la validación experimental que demuestra mejoras significativas en las tasas de error de orientación con configuraciones en tiempo real, especialmente en escenarios de alta tensión. La charla destacará las ventajas prácticas de los sistemas en tiempo real para mejorar la conciencia situacional y la calidad de interacción en la robótica social.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1140;">11:40</h3>

	<div class="session session-19 track-1" style="grid-column: track-1; grid-row: time-1140 / time-1155;">
		<span class="session-time">11:40 - 11:55</span>
		<span class="session-track">Paraninfo<br />Desarrollo y Despliegue en ROS: Diseño Basado en Modelos (MDD)</span>
		<br />
		<h4 class="session-title">Rossdl: Aplicación de tecnología basada en modelos (MDD) para la generación de Sistemas en ROS 2 </h4>
		<h4 class="session-presenter">
				Francisco Martín Rico (Universidad Rey Juan Carlos)
		</h4>
		<a href="https://github.com/ipa320/RosTooling" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://ipa320.github.io/RosTooling.github.io/" target="_blank" style="color:white" class="video-link">🌐 Leer más</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029493640" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Una de las grandes ventajas de la programación basada en modelos es la posibilidad de generar código. Estas herramientas potencian la unificación del desarrollo de nuevos componentes y además ahorran tiempo al desarrollador quien se puede concentrar en la programación de la lógica del software. Además, en ROS 2, evitan los errores comunes que llevan a falta de conectividad o de ejecución de nodos que hacen perder horas y horas de desarrollo. Por último, aplicaciones con más de 10-20 nodos comienzan a no poder manejarse por unos pocos desarrollodares sin herramientas adecuadas.</p>
<p>La propuesta de rossdl es partir de modelos formales que describen las propiedades de un paquete de ROS, generar sistemas y subsistemas en ROS 2.  Un solo fichero de descripción define un sistema: qué nodos, con qué publicadores/subscriptores, con qué QoS, etc... Este sistema puede formar parte de sistemas más grandes. La herramienta se encarga de generar la parte de la aplicaciones más tediosa y sujeta a errores, mientras que permite al programador centrarse en el desarrollo de la lógica de los sistemas, de manera que los detalles de la estructura del grafo o el deployment de la aplicación se puede hacer, incluso de sistemas grandes, evitando multitud de problemas.</p>
		</details>
	</div>

	<div class="session session-20 track-2" style="grid-column: track-2; grid-row: time-1140 / time-1155;">
		<span class="session-time">11:40 - 11:55</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />HRI y Robótica Social</span>
		<br />
		<h4 class="session-title">whisper_ros: Advanced Speech-to-Text for ROS 2 with SileroVAD and Quantized Whisper</h4>
		<h4 class="session-presenter">
				Miguel Ángel González Santamarta (Universidad de León)
		</h4>
		<a href="https://github.com/mgonzs13/whisper_ros" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029493035" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>El reconocimiento de voz o Speech-to-Text (STT) es una habilidad fundamental para la comunicación efectiva entre robots y personas. Los modelos Whisper de OpenAI han avanzado significativamente en este campo, y su uso optimizado a través de la cuantificación permite implementaciones eficientes. De esta forma, whisper_ros integra la librería whisper.cpp en ROS 2, facilitando el uso de estos modelos cuantificados en aplicaciones robóticas. Además, emplea SileroVAD para la detección de actividad de voz (VAD), mejorando la precisión del STT. Esta integración proporciona una solución basada en deep learning para transcribir voz a texto en sistemas basados en ROS 2, mejorando la interacción humano-robot en diversas aplicaciones.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1155;">11:55</h3>

	<div class="session session-21 track-1" style="grid-column: track-1; grid-row: time-1155 / time-1210;">
		<span class="session-time">11:55 - 12:10</span>
		<span class="session-track">Paraninfo<br />Desarrollo y Despliegue en ROS: Diseño Basado en Modelos (MDD)</span>
		<br />
		<h4 class="session-title">Aceleración del Desarrollo de Aplicaciones Robóticas en ROS con Diseño Basado en Modelos</h4>
		<h4 class="session-presenter">
				Jennifer J. Gago Muñoz (MathWorks)
		</h4>
		<a href="https://es.mathworks.com/help/ros/index.html" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://es.mathworks.com/solutions/model-based-design.html" target="_blank" style="color:white" class="video-link">🌐 Leer más</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029493058" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>RESUMEN:</p>
<p>El diseño basado en modelos (MBD) es un enfoque del desarrollo de sistemas complejos que integra simulación, validación y generación automática de código. Cuando se aplica a ROS, MBD facilita el diseño, el análisis y la implementación de aplicaciones robóticas y fomenta la reutilización de componentes de software. Aprovechando la ROS Toolbox desarrollada por MathWorks y utilizándola junto con MATLAB® y Simulink®, los ingenieros e investigadores pueden diseñar modelos detallados de sistemas robóticos en un entorno virtual, simular y probar algoritmos, generar automáticamente código optimizado e implantar nodos ROS en hardware.</p>
<p>DESCRIPCIÓN:</p>
<ol>
<li>Introducción</li>
</ol>
<p>El desarrollo de sistemas robóticos plantea retos únicos debido a su complejidad y a la necesidad de integrar componentes de software y hardware. El diseño basado en modelos ofrece una solución que permite a los ingenieros diseñar modelos detallados de sistemas robóticos en un entorno virtual. Este enfoque no sólo ofrece una simulación exhaustiva y la validación de algoritmos en diversos escenarios, sino que también facilita la generación automática de código optimizado para su despliegue en objetivos de hardware embebido.</p>
<ol>
<li>Diseño basado en modelos aplicado a ROS</li>
</ol>
<p>El diseño basado en modelos [1] se basa en el uso de herramientas de modelado y simulación como MATLAB® y Simulink®, que proporcionan una plataforma para el diseño de sistemas robóticos. Los ingenieros pueden simular interacciones complejas entre componentes de software y hardware, e identificar y corregir posibles errores en una fase temprana del ciclo de desarrollo. La metodología también permite generar código a partir de modelos, lo que facilita la transición del diseño a la implementación.</p>
<p>La aplicación de MBD en el ecosistema ROS optimiza el flujo de trabajo de diseño, análisis e implantación de aplicaciones robóticas, al tiempo que promueve una arquitectura de software modular y reutilizable. Esta sinergia entre MBD y ROS acelera el proceso de desarrollo y mejora la robustez y mantenibilidad de los componentes de software. Esta metodología promueve un enfoque de ingeniería riguroso que permite la optimización continua del rendimiento y la fiabilidad de los sistemas robóticos.</p>
<p>Las herramientas ofrecidas por MathWorks, como MATLAB® y Simulink®, proporcionan una plataforma para ingenieros e investigadores implicados en el modelado y la simulación de sistemas robóticos. Estas herramientas proporcionan un entorno de desarrollo integrado para el diseño de modelos detallados, lo que permite realizar simulaciones fieles y probar algoritmos bajo diversas restricciones y escenarios. La ventaja de estos entornos reside en su capacidad para simular interacciones complejas entre distintos componentes de software, lo que facilita la identificación temprana de problemas y la optimización de soluciones.</p>
<p>La generación automática de código a partir de modelos desarrollados mediante MBD acelera el proceso de implementación de algoritmos, desde la simulación hasta la ejecución en las plataformas de hardware de destino.</p>
<p>La integración del diseño basado en modelos en el proceso de desarrollo de la robótica también ofrece soluciones a una serie de retos emergentes. Entre ellos se incluyen la incorporación de la IA a los sistemas robóticos, el trabajo colaborativo entre ingenieros de sistemas y de software, la mejora de la automatización en las prácticas DevOps y el uso eficaz del gemelo digital para la predicción y optimización del rendimiento y los recursos del sistema.</p>
<ol>
<li>La ROS Toolbox en el mundo MBD</li>
</ol>
<p>La ROS Toolbox [2,3] proporciona una interfaz que enlaza MATLAB® y Simulink® con ROS y ROS 2. Con esta Toolbox, los ingenieros e investigadores pueden diseñar una red de nodos ROS y combinar nodos ROS generados por MATLAB® o Simulink® con una red ROS existente.</p>
<p>La Toolbox incluye funciones y bloques para visualizar y analizar datos ROS guardando, importando y reproduciendo archivos rosbag. También es posible conectarse directamente a una red ROS para acceder y enviar mensajes en tiempo real. Además, ROS Toolbox permite verificar nodos ROS mediante simulación por ordenador, simuladores externos como Gazebo, o mediante una conexión a hardware real.</p>
<p>Por último, la Toolbox admite la generación de código C++ y CUDA®, lo que permite generar automáticamente nodos ROS a partir de un script de MATLAB® o un modelo de Simulink® e implantarlos en el robot real. La compatibilidad con el modo externo de Simulink® permite visualizar mensajes y modificar parámetros mientras el modelo se ejecuta en el hardware.</p>
<p>Esta capacidad de generar código optimizado que puede desplegarse directamente en sistemas embebidos representa una baza importante para la investigación y el desarrollo en robótica, ya que reduce el tiempo necesario para la iteración entre el diseño teórico y la validación experimental. En consecuencia, la integración de MBD en los proyectos de investigación e ingeniería en robótica promueve un enfoque más sistemático y eficiente, propicio para el avance tecnológico y la innovación en el campo de la robótica.</p>
<ol>
<li>Referencias</li>
</ol>
<p>[1] Enfoque de diseño basado en modelos - MATLAB &amp; Simulink - https://es.mathworks.com/solutions/model-based-design.html
[2] Documentación de ROS Toolbox - https://es.mathworks.com/help/ros/index.html
[3] Lista de ejemplos de ROS Toolbox - https://es.mathworks.com/help/ros/examples.html</p>
		</details>
	</div>

	<div class="session session-22 track-2" style="grid-column: track-2; grid-row: time-1155 / time-1210;">
		<span class="session-time">11:55 - 12:10</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />HRI y Robótica Social</span>
		<br />
		<h4 class="session-title">Detección de personas utilizando LiDAR 2D, machine learning y ROS</h4>
		<h4 class="session-presenter">
				Fernando Amodeo Zurbano (Universidad Pablo de Olavide)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492514" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Los robots móviles han de tener conocimiento de su entorno, especialmente cuando hay personas en su vecindad. Aunque los métodos más utilizados para detectar personas involucran el uso de visión por computador; una característica a menudo olvidada de los robots que se podría utilizar también son sus sensores LiDAR 2D. En la mayoría de robots se encuentran a la altura aproximadamente entre el tobillo y la rodilla, por lo que también se pueden utilizar para detectar personas, y con un rango de visión y de profundidad mayor que el de las cámaras.</p>
<p>En esta charla presentamos un nuevo dataset para detección de personas utilizando LiDAR 2D llamado FROG; el cual presenta sustanciales mejoras en cuanto a resolución, frecuencia de escaneado, duración, y calidad de anotación comparado con datasets ya existentes (DROW). Asimismo, presentamos modelos end-to-end basados en Machine Learning para la detección de personas, los cuales no requieren de preprocesamiento en la entrada. Finalmente, presentamos nuestra implementación optimizada y encapsulada como nodo de ROS, la cual es capaz de operar bajo frecuencias superiores a 500 Hz.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1210;">12:10</h3>

	<div class="session session-23 track-1" style="grid-column: track-1; grid-row: time-1210 / time-1225;">
		<span class="session-time">12:10 - 12:25</span>
		<span class="session-track">Paraninfo<br />Desarrollo y Despliegue en ROS</span>
		<br />
		<h4 class="session-title">Novedades en la libreria cliente RCLAda</h4>
		<h4 class="session-presenter">
				Alejandro Mosteo Chagoyen (Centro Universitario de la Defensa de Zaragoza)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493544" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>La librería RCLAda es un cliente para ROS 2, equivalente a RCLCPP y RCLPy, para el lenguaje Ada y su subconjunto formalmente verificable SPARK. Recientemente ha sido actualizada para la última versión estable de ROS 2, Humble Hawksbill, incorporando nuevas funcionalidades como soporte de transformadas (tf). En esta charla se presentarán las características singulares de la librería que la pueden hacer atractiva para desarrolladores orientados al software de alta integridad como el que encontramos en satélites, aviones, sistemas médicos, etc.</p>
	</div>

	<div class="session session-24 track-2" style="grid-column: track-2; grid-row: time-1210 / time-1225;">
		<span class="session-time">12:10 - 12:25</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />HRI y Robótica Social</span>
		<br />
		<h4 class="session-title">Percepción multimodal para Aplicaciones de Interacción Humano-Robot Social </h4>
		<h4 class="session-presenter">
				Josep Bravo (Eurecat)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492811" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Este trabajo multi-modal optimiza la eficacia y calidad de la percepción de alto nivel del robot, permitiéndole alcanzar una cognición de su entorno y del contexto similar a la humana. Incluye diálogos personalizados y feedback para ejercicios físicos, ajustando su atención y seguimiento visual según la persona con la que interactúa. Utiliza sensores integrados, cámaras RGBD y lidar, procesados a través de ROS. También intercomunica módulos para gestionar información detallada de objetos y sujetos humanos en tiempo real, integrando funcionalidades como detección y seguimiento de objetos y interpretar su significado semántico, reconocimiento facial, análisis de los puntos clave del movimiento humano, y reconocimiento de voz junto con gestión de historial conversacional.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1225;">12:25</h3>

	<div class="session session-25 track-all" style="grid-column: track-1-start / track-2-end; grid-row: time-1225 / time-1235;">
		<span class="session-time">12:25 - 12:35</span>
		<br />
		<h4 class="session-title">Shuffle</h4>
	</div>

	<h3 class="time-slot" style="grid-row: time-1235;">12:35</h3>

	<div class="session session-26 track-1" style="grid-column: track-1; grid-row: time-1235 / time-1250;">
		<span class="session-time">12:35 - 12:50</span>
		<span class="session-track">Paraninfo<br />Desarrollo y Despliegue en ROS</span>
		<br />
		<h4 class="session-title">BT-Studio: programando aplicaciones robóticas con ROS 2 y Behavior Trees</h4>
		<h4 class="session-presenter">
				José María Cañas Plaza (JdeRobot Organization)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493165" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>BT Studio es una herramienta de código abierto diseñada para el desarrollo de aplicaciones robóticas en ROS 2. Facilita el despliegue de aplicaciones basadas en árboles de comportamiento mediante un árbol gráfico y acciones programadas en Python, que se convierten en paquetes de ROS 2 totalmente funcionales. Esta herramienta permite una integración eficiente con otros componentes de ROS 2 y simplifica el desarrollo y la depuración de aplicaciones robóticas complejas.</p>
	</div>

	<div class="session session-27 track-2" style="grid-column: track-2; grid-row: time-1235 / time-1245;">
		<span class="session-time">12:35 - 12:45</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />HRI y Robótica Social</span>
		<br />
		<h4 class="session-title">ROS 2 en competiciones robóticas: Una arquitectura para Robots Sociales</h4>
		<h4 class="session-presenter">
				Juan Diego Peña Narvaez (Universidad Rey Juan Carlos)
		</h4>
		<a href="https://github.com/CoreSenseEU/CoreSense4Home" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029492964" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>Se explorará el desarrollo de una arquitectura software para robots sociales en el contexto de competiciones, haciendo uso de ROS 2. Se abordarán los diversos desafíos encontrados y cómo a partir de estos diseñar una arquitectura eficiente.</p>
<p>Se detallará la arquitectura propuesta, explicando las decisiones tomadas en su diseño y los compromisos involucrados. Además, se presentarán los resultados obtenidos en la competición RoboCup@Home 2024. Se proporcionarán recursos sobre cómo coordinar  comportamientos robóticos complejos, el manejo de percepciones, la interacción humano-robot, la navegación y la manipulación.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1245;">12:45</h3>

	<div class="session session-28 track-2" style="grid-column: track-2; grid-row: time-1245 / time-1255;">
		<span class="session-time">12:45 - 12:55</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />HRI y Robótica Social</span>
		<br />
		<h4 class="session-title">Integración de robots en entornos de vida asistiva (AAL)</h4>
		<h4 class="session-presenter">
				Alberto Tudela Roldán (Universidad de Málaga)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492660" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>Propuesta de integración de un robot SAR en entornos de vida diaria asistida en los que se extiende la capacidad de percepción y navegación de un robot mediante una arquitectura cognitiva.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1250;">12:50</h3>

	<div class="session session-29 track-1" style="grid-column: track-1; grid-row: time-1250 / time-1305;">
		<span class="session-time">12:50 - 13:05</span>
		<span class="session-track">Paraninfo<br />Simulación</span>
		<br />
		<h4 class="session-title">Simulador en Gazebo para un Sistema Robótico Marsupial UAV-UGV con Planificación de Trayectoria Basada en ROS 2</h4>
		<h4 class="session-presenter">
				José Enrique Maese Álvarez (Universidad Pablo de Olavide)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493734" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>En esta charla se presentará el desarrollo de un simulador, en el entorno de Gazebo y ROS 2, para un sistema robótico marsupial compuesto por un vehículo aéreo no tripulado (UAV) y un vehículo terrestre no tripulado (UGV) conectados por un cable flexible modelado como una sucesión de cilindros unidos. El principal objetivo es crear un entorno de simulación robusto que permita probar y validar el comportamiento y la interacción del sistema marsupial UAV-UGV bajo diversas condiciones y escenarios. Aprovechando las capacidades de ROS 2, el simulador facilita la evaluación de metodologías innovadoras para la operación coordinada y autónoma de ambos robots, incluyendo la dinámica del cable flexible que los conecta.
Este simulador proporciona una plataforma diseñada para el análisis y la optimización del sistema robótico marsupial. Permite simular no solo la planificación de trayectorias, sino también la respuesta a diversas fuerzas que afectan la operación conjunta del UAV y el UGV. Además, el simulador está diseñado para generar escenarios realistas donde se pueden observar los efectos de las interacciones físicas entre el UAV, el UGV y el cable flexible. Este enfoque no solo mejora la comprensión del sistema en situaciones complejas y dinámicas, sino que también abre nuevas posibilidades para aplicaciones donde la colaboración entre diferentes plataformas robóticas es esencial.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1305;">13:05</h3>

	<div class="session session-30 track-1" style="grid-column: track-1; grid-row: time-1305 / time-1320;">
		<span class="session-time">13:05 - 13:20</span>
		<span class="session-track">Paraninfo<br />Simulación</span>
		<br />
		<h4 class="session-title">Diseñando el futuro: Robots que crean herramientas con ROS 2</h4>
		<h4 class="session-presenter">
				Virgilio Gómez Lambo (Universidad Politécnica de Madrid)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493251" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>En esta charla, discutiremos cómo generar formas para la impresión 3D, enviarlas a la impresora y luego generarlas en Isaac Sim. Además, hablaremos sobre el proyecto MetaTool, que tiene como objetivo proporcionar un modelo computacional de conciencia sintética para mejorar la adaptación y lograr la invención de herramientas. Este proyecto permitirá a un robot monitorear y autoevaluar su rendimiento, utilizar esta información para adaptarse a nuevas circunstancias y, finalmente, desbloquear la posibilidad de crear nuevas herramientas.</p>
<p>Bajo el enfoque predictivo de la conciencia, y basándonos en evidencia tanto neurocientífica como arqueológica, desarrollaremos un nuevo modelo computacional de metacognición basado en el procesamiento predictivo (metapredicción) y validaremos su utilidad en robots reales en dos escenarios de uso: tareas secuenciales condicionales y creación de herramientas.</p>
<p>La integración con ROS (Robot Operating System) es crucial para conectar todas estas tecnologías y garantizar una comunicación fluida entre los diferentes componentes del sistema. Utilizaremos ROS 2 para:</p>
<p>1.Controlar y monitorizar los robots en tiempo real.</p>
<p>2.Procesar y analizar datos de sensores y cámaras.</p>
<p>3.Enviar comandos de control a los manipuladores UR.</p>
<p>4.Integrar el sistema de visión por cámara con Isaac Sim y ROS.</p>
<p>5.Crear formas 3D utilizando un lenguaje de descripción como URDF o un lenguaje similar y comunicar estas formas con la impresora 3D y el simulador Isaac Sim.</p>
<p>Los asistentes aprenderán a:</p>
<p>1.Comprender los conceptos básicos del proyecto MetaTool y su objetivo en la creación de herramientas.</p>
<p>2.Generar y enviar formas para la impresión 3D utilizando ROS.</p>
<p>3.Integrar estas formas en simulaciones usando Isaac Sim.</p>
<p>4.Utilizar ROS y URDF o un lenguaje de descripción similar para describir y comunicar formas 3D a una impresora 3D y a Isaac Sim.</p>
<p>Esta charla proporcionará una visión general rápida pero completa sobre cómo estas tecnologías avanzadas pueden integrarse y aplicarse en la robótica moderna. </p>
		</details>
	</div>

	<div class="session session-31 track-2" style="grid-column: track-2; grid-row: time-1305 / time-1315;">
		<span class="session-time">13:05 - 13:15</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />HRI y Robótica Social</span>
		<br />
		<h4 class="session-title">Localización en tiempo real por UWB (Ultra-Wide band) para aplicaciones con interacción humano-robot</h4>
		<h4 class="session-presenter">
				Maria del Mar Plaza Cano (Universitat Politécnica de València)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492699" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>En la charla se abordará cómo mejorar la interacción humano-robot (HRI) en entornos de trabajo mediante la implementación de sistemas de localización en tiempo real (RTLS), específicamente utilizando la tecnología de banda ultra ancha (UWB). Para ello, se ha desarrollado un módulo ROS que integra la información de posicionamiento de diversos tags en la arquitectura ROS de robots móviles. Con esto, se pueden generar obstáculos en el planificador del robot a partir de sensores virtuales, es decir, el robot puede evitar obstáculos que no logra ver con sus sensores convencionales. Se presentarán algunas de las posibles aplicaciones, como evitación de obstáculos, optimización de trayectorias o seguimiento de operarios.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1315;">13:15</h3>

	<div class="session session-32 track-2" style="grid-column: track-2; grid-row: time-1315 / time-1325;">
		<span class="session-time">13:15 - 13:25</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />HRI y Robótica Social</span>
		<br />
		<h4 class="session-title">Interacción humano-dron mediante modelos de segmentación promptable para inspección aérea semiautónoma</h4>
		<h4 class="session-presenter">
				Riccardo Franceschini (Eurecat)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492677" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>En esta presentación, introduciremos un paradigma de interacción innovador para aprovechar modelos de segmentación promptable en la inspección visual aérea. El enfoque se centra en cómo estos modelos novedosos, combinados con interfaces de realidad aumentada (AR), pueden agilizar el proceso de definición e inspección de superficies. Analizaremos la interacción propuesta entre operadores y UAVs, destacando sus ventajas distintivas y demostrando cómo ROS facilitó el desarrollo de este esquema de interacción.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1320;">13:20</h3>

	<div class="session session-33 track-1" style="grid-column: track-1; grid-row: time-1320 / time-1335;">
		<span class="session-time">13:20 - 13:35</span>
		<span class="session-track">Paraninfo<br />Simulación</span>
		<br />
		<h4 class="session-title">MVSim: simulando de manera fácil robots terrestres</h4>
		<h4 class="session-presenter">
				Jose Luis Blanco Claraco (Universidad de Almería)
		</h4>
		<a href="https://github.com/MRPT/mvsim_docker_example" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029493515" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>Una introducción a este nuevo simulador 2.5D de vehículos y AGVs disponible para ROS 1 Y ROS 2, cómo se definen los modelos de robots y los "mundos", y ejemplos de uso de sensores (cámaras, RGBD, 3D LiDAR). Uso en containers y para unit tests en pipelines de Continous Integration (CI).</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1325;">13:25</h3>

	<div class="session session-34 track-2" style="grid-column: track-2; grid-row: time-1325 / time-1335;">
		<span class="session-time">13:25 - 13:35</span>
		<span class="session-track">Sala de Grados, Ed. 7</span>
		<br />
		<h4 class="session-title">Análisis de transitabilidad e interfaz para planificación y monitorización de robots</h4>
		<h4 class="session-presenter">
				Pablo Gómez-Cambronero Martín (Robotnik)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492431" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>Explora cómo los robots autónomos evalúan y navegan su entorno mediante el análisis de transitabilidad. Descubre las funcionalidades clave de este análisis, desde la detección de obstáculos hasta la planificación de rutas seguras. Además, conoce una interfaz innovadora para la planificación y monitorización en tiempo real de robots, presentando casos de estudio en aplicaciones del mundo real.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1335;">13:35</h3>

	<div class="session session-35 track-all" style="grid-column: track-1-start / track-2-end; grid-row: time-1335 / time-1505;">
		<span class="session-time">13:35 - 15:05</span>
		<span class="session-track">Paraninfo</span>
		<br />
		<h4 class="session-title">Comida</h4>
	</div>

	<h3 class="time-slot" style="grid-row: time-1505;">15:05</h3>

	<div class="session session-36 track-1" style="grid-column: track-1; grid-row: time-1505 / time-1520;">
		<span class="session-time">15:05 - 15:20</span>
		<span class="session-track">Paraninfo<br />Multi-Robot</span>
		<br />
		<h4 class="session-title">Aplicación de Open-RMF en Robots Reales: Experiencias y Retos</h4>
		<h4 class="session-presenter">
				Sandra Moreno Olivares (Robotnik)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493101" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Se presentará una experiencia práctica de uso real del Open-RMF en ROS2 Humble para la gestión de flotas robóticas, abarcando tanto escenarios simulados como aplicaciones reales en varios casos de uso. Se mostrará y compartirá el repositorio de GitHub de código abierto del adaptador desarrollado específicamente para nuestra flota robótica, incluyendo ejemplos de código reales y funcionales. Además, se exhibirá el despliegue real llevado a cabo para nuestros robots empleando tecnologías como ROS 1, ROS 2, MQTT y Docker. Durante la presentación, se analizarán los desafíos encontrados durante el proceso, se compartirán las lecciones aprendidas, las limitaciones actuales y se discutirán las perspectivas futuras para optimizar la gestión de flotas robóticas utilizando el gestor de flotas Open-RMF.</p>
		</details>
	</div>

	<div class="session session-37 track-2" style="grid-column: track-2; grid-row: time-1505 / time-1520;">
		<span class="session-time">15:05 - 15:20</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />Mapping y SLAM</span>
		<br />
		<h4 class="session-title">3D LIDAR SLAM en nube y edge usando ROS2 y Kubernetes</h4>
		<h4 class="session-presenter">
				Guillem Gari Zanon (Robotnik)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492400" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>Se va a exponer el uso de 3D SLAM basado 360 LIDAR en ROS2, tanto en el modo de construcción de mapas como en la localización en tiempo real, basado en tecnología nativa de la nube. En concreto, se mostrará cómo desplegar Cartographer utilizando Kubernetes o Docker Swarm, y cómo comunicar robots basados en ROS2. Se expondrá un método para comunicar cargas de trabajo de ROS2 a remotas a través de Internet o redes bajo cortafuegos, basado en WebSockets. Se mostrarán resultados con robots reales que utilizan localización en tiempo real en un equipo remoto.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1520;">15:20</h3>

	<div class="session session-38 track-1" style="grid-column: track-1; grid-row: time-1520 / time-1530;">
		<span class="session-time">15:20 - 15:30</span>
		<span class="session-track">Paraninfo<br />Multi-Robot</span>
		<br />
		<h4 class="session-title">Coordinación de Robots para la Inspección de Infraestructuras Críticas</h4>
		<h4 class="session-presenter">
				Álvaro Calvo Matos (Universidad de Sevilla)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493226" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Presentamos un framework para coordinar robots heterogéneos realizando tareas de inspección de infraestructuras críticas. Para el modelado de comportamientos de alto nivel y ejecución de misiones con gestión de fallos se utilizan Behavior Trees (BTs). La arquitectura se articula a través de ROS utilizando la librería ActionLib, entre otras. Nuestra solución permite la planificación, ejecución y supervisión eficiente de misiones cooperativas, asignando tareas según las capacidades de cada robot y gestionando recursos de manera efectiva. Mostraremos la implementación práctica de este framework a través de videos experimentales en instalaciones eléctricas y fotovoltaicas, destacando su aplicabilidad y beneficios en entornos reales. Esta charla proporcionará una visión de cómo estas herramientas de ROS pueden optimizar la inspección de infraestructuras críticas.</p>
		</details>
	</div>

	<div class="session session-39 track-2" style="grid-column: track-2; grid-row: time-1520 / time-1540;">
		<span class="session-time">15:20 - 15:40</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />Mapping y SLAM</span>
		<br />
		<h4 class="session-title">MOLA LiDAR odometry: ecosistema de paquetes para mapeo 3D</h4>
		<h4 class="session-presenter">
				José Luis Blanco Claraco (Universidad de Almería)
		</h4>
		<a href="https://github.com/MOLAorg/mola" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029492724" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>Introducción al nuevo método (a publicar pronto) para construcción de mapas 3D , odometría lidar, visualizadores de mapas 3D, pipelines de filtrado de nubes de puntos, etc.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1530;">15:30</h3>

	<div class="session session-40 track-1" style="grid-column: track-1; grid-row: time-1530 / time-1545;">
		<span class="session-time">15:30 - 15:45</span>
		<span class="session-track">Paraninfo<br />Multi-Robot</span>
		<br />
		<h4 class="session-title">ROS para Cinematografía Autónoma con Drones y Cámaras Avanzadas</h4>
		<h4 class="session-presenter">
				Pablo Pueyo Ramón (Universidad de Zaragoza)
		</h4>
		<a href="https://github.com/ppueyor/CineMPC_ros" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029493625" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>En esta charla se describirán los detalles teóricos y de integración de la plataforma con drones con fines cinematográficos CineMPC, que incorpora como novedad los parámetros intrínsecos como parte del sistema de control. Esta plataforma fue publicada en el artículo 'CineMPC: A Fully Autonomous Drone Cinematography System Incorporating Zoom, Focus, Pose, and Scene Composition' en la revista Transactions on Robotics 2024. Además, el código está publicado libremente para uso de la comunidad.</p>
<p>La charla estará dividida en dos partes. Por un lado, y como introducción a la parte más técnica o de implementación, se describirán las cuestiones teóricas para el desarrollo de un sistema que logra la autonomía completa de una plataforma para un dron con fines cinematográficos. Este sistema presenta novedosos avances en los efectos cinematográficos controlados y ejecutados, como el control del enfoque y del zoom de la cámara, que no se habían tenido en cuenta en soluciones anteriores.</p>
<p>En la segunda parte de la charla se describirán al detalle las cuestiones técnicas de implementación en ROS de la plataforma descrita. Primero, se comentará cómo se ha implementado el sistema siguiendo una arquitectura modular en ROS, permitiendo la ejecución y evaluación de los diferentes módulos del sistema de forma independiente, y describiendo cada uno de los nodos y topics de ROS más relevantes del sistema.</p>
<p>Una vez descrita la arquitectura, se explicará cómo se ha realizado la evaluación del sistema tanto en simulación como con una plataforma real, donde se ha dotado a ambos sistemas con herramientas y programación en ROS para una comunicación que sea agnóstica a la plataforma utilizada.</p>
<p>Primero, se explicará cómo se ha desarrollado la extensión del simulador robótico AirSim para incluir estos efectos en sus drones, y se mostrarán diversas pruebas en simulación del sistema propuesto. Para finalizar, se debatirán los pasos a seguir para la ejecución en una plataforma real con un dron y cámara cinematográfica e integración en el sistema modular planteado en ROS.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1540;">15:40</h3>

	<div class="session session-41 track-2" style="grid-column: track-2; grid-row: time-1540 / time-1600;">
		<span class="session-time">15:40 - 16:00</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />Mapping y SLAM</span>
		<br />
		<h4 class="session-title">Generación de espacios 3D mediante robots autónomos en tiempo real</h4>
		<h4 class="session-presenter">
				Pablo Manuel Guzmán Manzanares (CATEC - Centro Avanzado de Tecnologías Aeroespaciales)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492602" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>El proyecto "Generación de espacios 3D mediante robots autónomos en tiempo real" consiste en el desarrollo de un pipeline para la creación de mallas 3D en tiempo real a partir de la información proporcionada por un vehículo autónomo equipado con sensores IMU y LIDAR. Se utilizan las ventajas que proporciona ROS para facilitar la transmisión de información entre los diferentes módulos de procesamiento desarrollados..
Entre las características principales del desarrollo se incluye la configuración e integración de LIO-SAM para la extracción de nubes de puntos, así como el uso de las bibliotecas Open3D y PCL para el procesamiento avanzado de estas nubes. Además, se abordan las metodologías y algoritmos implementados en el proyecto para la reconstrucción de mallas de grandes superficies en entornos de tiempo real y la configuración y diseño de pipelines en ROS.
Para obtener datos LiDAR precisos, se aplican técnicas avanzadas de segmentación y filtrado para mejorar la calidad de estos datos, y la implementación de algoritmos de reconstrucción para convertir nubes de puntos en mallas tridimensionales. Además, se desarrolla un pipeline capaz de operar con un gran volumen de datos en tiempo real, permitiendo la visualización y análisis inmediatos de los datos procesados.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1545;">15:45</h3>

	<div class="session session-42 track-1" style="grid-column: track-1; grid-row: time-1545 / time-1600;">
		<span class="session-time">15:45 - 16:00</span>
		<span class="session-track">Paraninfo<br />Multi-Robot</span>
		<br />
		<h4 class="session-title">Simulación Multiagente para el Arbitraje y Cooperación de Sistemas de Transporte Inteligentes</h4>
		<h4 class="session-presenter">
				David Yagüe Cuevas (Universidad Carlos III de Madrid)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493707" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>En esta charla se propone enfocar el desarrollo y la investigación de los Sistemas de Transporte Inteligentes desde un punto de vista cooperativo-colaborativo gracias a las posibilidades distribuidas de ROS. Para ello se presentarán una combinación de herramientas basadas en ROS y Carla para la simulación de múltiples agentes cooperativos funcionando de manera concurrente bajo el mismo entorno en tiempo real. Se expondrá la base fundacional del framework desarrollado y sus posibilidades para la futura investigación sobre Vehículos automáticos conectados y cooperativos. Finalmente, se presentará un conjunto de videos demostrativos a fin de exponer las capacidades colaborativas del entorno propuesto.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1600;">16:00</h3>

	<div class="session session-43 track-all" style="grid-column: track-1-start / track-2-end; grid-row: time-1600 / time-1610;">
		<span class="session-time">16:00 - 16:10</span>
		<br />
		<h4 class="session-title">Shuffle</h4>
	</div>

	<h3 class="time-slot" style="grid-row: time-1610;">16:10</h3>

	<div class="session session-44 track-1" style="grid-column: track-1; grid-row: time-1610 / time-1620;">
		<span class="session-time">16:10 - 16:20</span>
		<span class="session-track">Paraninfo</span>
		<br />
		<h4 class="session-title">Recolección inteligente de frutos mediante robots</h4>
		<h4 class="session-presenter">
				Óscar Palacín Domínguez (Eurecat)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493592" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>Esta charla presentará un enfoque innovador basado en ROS para la manipulación inteligente de frutas. Basado en Moveit!, Behavior Tree y modelos basados en IA de detección y segmentación, la solución desarrollada es capaz de detectar de forma autónoma los frutos objetivo y su nivel de madurez a lo largo del cultivo, estimar la posición y orientación de los maduros, y recolectarlos sin colisionar con el entorno. El marco también incluye un panel de control, basado en MySQL, para supervisar el estado de la tarea de recolección.</p>
	</div>

	<div class="session session-45 track-2" style="grid-column: track-2; grid-row: time-1610 / time-1625;">
		<span class="session-time">16:10 - 16:25</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />Drones</span>
		<br />
		<h4 class="session-title">Exploración de entornos no estructurados usando sensores mínimos en nano-drones cooperativos</h4>
		<h4 class="session-presenter">
				Pedro Arias Pérez (Universidad Politécnica de Madrid)
		</h4>
		<a href="https://github.com/pariaspe/minimal_sensing_exploration" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029492555" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Recientes avances han mejorado la navegación autónoma y el mapeo bajo restricciones de carga útil, pero los algoritmos actuales de inspección multi-robot no son adecuados para nano-drones debido a su necesidad de sensores pesados y altos recursos computacionales. Para abordar estos desafíos, esta charla presenta ExploreBug, un novedoso algoritmo que fusiona la exploración por fronteras con algoritmos tipo insecto, diseñado para manejar un enjambre de nano-drones con sensores limitados en tareas de exploración.</p>
<p>La arquitectura del sistema está construida sobre ROS 2 y Aerostack2, proponiendo nuevos subsistemas que introducen el mapeado, la navegación o la evasión de colisiones intra-enjambre siguiendo el estándar de comportamientos de Aerostack2.</p>
<p>Validamos la eficacia de nuestro enfoque a través de extensas simulaciones y experimentos de exploración en el mundo real que involucran hasta siete drones en simulaciones y tres en entornos reales, a través de diversas configuraciones de obstáculos. Nuestras pruebas demuestran que el algoritmo completa eficientemente las tareas de exploración, incluso con un sensado mínimo, en diferentes tamaños de enjambre y densidades de obstáculos. Además, nuestra heurística de asignación de fronteras asegura una distribución equitativa de áreas exploradas y caminos recorridos por cada dron en el enjambre. </p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1620;">16:20</h3>

	<div class="session session-46 track-1" style="grid-column: track-1; grid-row: time-1620 / time-1630;">
		<span class="session-time">16:20 - 16:30</span>
		<span class="session-track">Paraninfo<br />Plataformas</span>
		<br />
		<h4 class="session-title">Instrumentación de un robot en ROS 2</h4>
		<h4 class="session-presenter">
				Juan Carlos Manzanares Serrano (Universidad Rey Juan Carlos)
		</h4>
		<a href="https://github.com/CoreSenseEU/coresense_instrumentation" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029493394" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>En la charla se presentará el paquete Coresense Instrumentation. Este permite realizar la instrumentación de una plataforma en ROS 2, dotada de sensores y actuadores, para poder llevar a cabo la implementacion de mecanismos de autoconciencia y autocontrol. Algunas de las funcionalidades de este paquete son:
- Controladores virtuales para cada sensor/actuador.
- Activacion/desactivación de cada uno de estos controladores.
- Generacion de nuevos flujos (topics).
- Introspección.
- GUI.
- ros2cli</p>
<p>Además, se hablará de la plataforma SteamDeck, elemento muy utilizado ultimamente por los desarrolladores de ROS 2 que quieren controlar sus robots a la vez visualizar la información de los sensores. Se explicará brevemente como preparar todo el entorno, las posbilidades de uso de esta, y como se ha utilizado junto con la instrumentación para que pueda llevar a cabo todas las funcionalidades descritas anteriormente.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1625;">16:25</h3>

	<div class="session session-47 track-2" style="grid-column: track-2; grid-row: time-1625 / time-1640;">
		<span class="session-time">16:25 - 16:40</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />Drones</span>
		<br />
		<h4 class="session-title">Gazebo-in-the-loop para testeo de Drone Real en cuevas simuladas</h4>
		<h4 class="session-presenter">
				Lorenzo Cano (Universidad de Zaragoza)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492579" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>Método para probar un sistema de navegación de UAVs en túneles sin tener que desplegar el UAV en un túnel per-se. Emplea el UAV real, que vuela dentro de un entorno seguro y equipado con opti-track. Las mediciones del opti-track se emplean entonces para posicionar un modelo del UAV en Gazebo (situado en un túnel simulado), del cual se obtienen las mediciones LiDAR, a través de las cuales se computan los comandos de velocidad enviados al UAV.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1630;">16:30</h3>

	<div class="session session-48 track-1" style="grid-column: track-1; grid-row: time-1630 / time-1645;">
		<span class="session-time">16:30 - 16:45</span>
		<span class="session-track">Paraninfo<br />Plataformas</span>
		<br />
		<h4 class="session-title">Andino: un robot educativo de código abierto</h4>
		<h4 class="session-presenter">
				Javier Balloffet (Ekumen)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493081" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Andino es un robot diseñado e impulsado por Ekumen cuyo hardware, firmware y software son totalmente abiertos y gratuitos. Es una plataforma educativa de bajo costo (menos de 300€) y que permite tanto a personas nuevas como a las experimentadas en el campo de la robótica aprender, utilizar y experimentar con librerías de código estándar en el ecosistema de ROS 2, simuladores de robótica, empaquetado de aplicaciones y muchas cosas más.
El proyecto se convirtió en una pequeña comunidad que ha trascendido a nuestra empresa y ha sido presentado ya en universidades en Latinoamérica, donde el presupuesto de los estudiantes es significativamente menor que en otras partes del mundo.
Esperamos poder presentar el proyecto, casos de uso e integraciones, sinergias existentes, e invitar a la audiencia a utilizarlo y formar parte de la comunidad.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1640;">16:40</h3>

	<div class="session session-49 track-2" style="grid-column: track-2; grid-row: time-1640 / time-1650;">
		<span class="session-time">16:40 - 16:50</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />Drones</span>
		<br />
		<h4 class="session-title">Navegación autónoma 3D con UAVs</h4>
		<h4 class="session-presenter">
				Jorge Bes Carreras (Universidad de Zaragoza)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492748" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Uno de los problemas que se encuentra cuando se desea verificar el funcionamiento de algún sistema implicado en la navegación 3D de robots es la falta de un stack de navegación 3D amigable como el que se tiene en 2D. En esta charla se propone una arquitectura modular que solucione este problema, demostrando su aplicabilidad con un ejemplo de navegación completamente autónoma con UAVs en 3D. Se ha integrado en ROS la librería de planificación OMPL, que ofrece una amplia variedad de planificadores globales del estado del arte. En cuanto a la percepción y mapeado, se ha optado por nubes de puntos y por Octomap. Dicha arquitectura ha sido probada tanto en simulación como en laboratorio, suponiendo en ambos casos que el problema de localización estaba resuelto (“ground truth” del simulador y un sistema Optitrack en el laboratorio).</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1645;">16:45</h3>

	<div class="session session-50 track-1" style="grid-column: track-1; grid-row: time-1645 / time-1700;">
		<span class="session-time">16:45 - 17:00</span>
		<span class="session-track">Paraninfo<br />Plataformas</span>
		<br />
		<h4 class="session-title">Sevillabot - aventuras de una familia sevillana en Cambridge</h4>
		<h4 class="session-presenter">
				Manuel Heredia Ortiz (Sevillabot)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493673" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>En Octubre de 2024 una familia sevillana con tres niños se inscribió como “Sevillabot” para participar en la competición internacional de robótica Piwars2024. El reto era desarrollar en seis meses un robot capaz de afrontar combates y carreras de obstáculos, de manipular objetos, localizarse y navegar, lanzar proyectiles y seguir automáticamente una línea.</p>
<p>La charla describe las decisiones de arquitectura, el desarrollo del robot y la propia competición en Cambridge el pasado Abril. A nivel hardware “Sevillabot” consta de una base móvil a la que se acoplan accesorios desmontables para las distintas pruebas. A nivel software, “Sevillabot” está basado en ROS2 foxy.</p>
<p>Una enriquecedora aventura en familia, realmente divertida, con un resultado inesperadamente exitoso: “Sevillabot” se clasificó en tercer lugar en su categoría, resultando ganador en dos de los siete pruebas. </p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1650;">16:50</h3>

	<div class="session session-51 track-2" style="grid-column: track-2; grid-row: time-1650 / time-1705;">
		<span class="session-time">16:50 - 17:05</span>
		<span class="session-track">Sala de Grados, Ed. 7</span>
		<br />
		<h4 class="session-title">Plataforma Integral Yellowfish ASV con ROS2: Hardware, Software y Aplicaciones Prácticas</h4>
		<h4 class="session-presenter">
				Manuel Eduardo Gantiva Osorio (Universidad Loyola Andalucía)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492889" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>La charla abordará la descripción del vehículo autónomo de superficie (ASV) llamado Yellowfish, iniciando con una descripción técnica del hardware, abordando los sensores que proporcionan datos, los actuadores que permiten la movilidad precisa, y las características físicas del vehículo, como dimensiones y peso. Por otra parte, se discutirán las comunicaciones Xbee y Wifi, que garantizan una operación robusta en flota. En la sección de software, se analizará tanto la integración de ROS2 como el núcleo de la arquitectura de control, el uso de Docker para la gestión de contenedores y su implementación en computadoras de placa reducida, y la implementación de Ardupilot y el paquete Mavros, esenciales para la navegación y control autónomo. También se presentarán aplicaciones prácticas del ASV, con herramientas de limpieza para la recolección de micro plásticos y la eliminación de hidrocarburos en aguas contaminadas.
La segunda parte de la charla se enfocará en la arquitectura basada en ROS2 para el control del movimiento de un solo ASV. Se abordarán las etapas de control, explicando cómo se diseñan e implementan los controladores y observadores planteados en la literatura que han sido validados experimentalmente. Se mostrarán resultados experimentales y comparaciones entre diferentes enfoques de control, destacando las ventajas de utilizar ROS2 en este contexto. Finalmente, se ofrecerán conclusiones sobre las capacidades y limitaciones de esta arquitectura, y se discutirán futuras direcciones de investigación y desarrollo en el campo de los vehículos autónomos de superficie.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1700;">17:00</h3>

	<div class="session session-52 track-1" style="grid-column: track-1; grid-row: time-1700 / time-1715;">
		<span class="session-time">17:00 - 17:15</span>
		<span class="session-track">Paraninfo<br />Plataformas</span>
		<br />
		<h4 class="session-title">Hemos adquirido un robot con ROS2, ¿y ahora qué?</h4>
		<h4 class="session-presenter">
				Abel Carnicero Mayo (Universidad de León)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493363" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>En la charla se detallarán las lecciones aprendidas asociadas a la compra, puesta en marcha y despliegue de un robot cuadrúpedo compatible con ROS 2. Durante la presentación, se revisará la problemática asociada a la "compatibilidad" detallada por la empresa, integración de nuevos componentes ROS 2 hasta que se despliega en el entorno de aplicación en espacios públicos pasando por los distintos retos afrontados; versiones de ROS, DDS, complicaciones de hardware, exploración de la interfaz, o funcionalidades no detalladas en el manual de instrucciones.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1705;">17:05</h3>

	<div class="session session-53 track-2" style="grid-column: track-2; grid-row: time-1705 / time-1715;">
		<span class="session-time">17:05 - 17:15</span>
		<span class="session-track">Sala de Grados, Ed. 7</span>
		<br />
		<h4 class="session-title">Análisis del impacto de la configuración del sistema en el rendimiento de aplicaciones realistas basadas en arquitecturas software sobre ROS 2</h4>
		<h4 class="session-presenter">
				Rodrigo Pérez Rodríguez (Universidad Rey Juan Carlos)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492458" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>En esta charla se presentará un trabajo en el que se ha analizado el impacto de distintos factores en el rendimiento de sistemas reales usando arquitecturas software basadas en ROS 2. Más concretamente, se han analizado métricas como la latencia del sistema, mensajes perdidos, o el uso de recursos (CPU, memoria) en función de variables como el sistema DDS usado, la configuración de la arquitectura (nodos topics, tipo de mensajes usados), o el uso de sistemas en tiempo real.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1715;">17:15</h3>

	<div class="session session-54 track-all" style="grid-column: track-1-start / track-2-end; grid-row: time-1715 / time-1745;">
		<span class="session-time">17:15 - 17:45</span>
		<span class="session-track">Paraninfo</span>
		<br />
		<h4 class="session-title">Coffee Break</h4>
	</div>

	<h3 class="time-slot" style="grid-row: time-1745;">17:45</h3>

	<div class="session session-55 track-1" style="grid-column: track-1; grid-row: time-1745 / time-1800;">
		<span class="session-time">17:45 - 18:00</span>
		<span class="session-track">Paraninfo<br />Comunicaciones en ROS</span>
		<br />
		<h4 class="session-title">ROS 2 sobre wireless: análisis de prestaciones</h4>
		<h4 class="session-presenter">
				Danilo Tardioli (Centro Universitario de la Defensa)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493607" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>La charla describe el comportamiento y las implicaciones que tiene usar ROS2 y DDS sobre una red wireless en conexiones punto a punto y multisalto analizando jitter, retraso end-to-end y el efecto de los parámetros de configuración del DDS</p>
	</div>

	<div class="session session-56 track-2" style="grid-column: track-2; grid-row: time-1745 / time-1805;">
		<span class="session-time">17:45 - 18:05</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />Aplicaciones</span>
		<br />
		<h4 class="session-title">Innovación y desafío: Robots colaborativos en los Campos de Arándanos</h4>
		<h4 class="session-presenter">
				Christian Chavez Vasquez (Robotnik)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492635" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>Usando la plataforma RB-VOGUI+ de Robotnik  se realiza un análisis de las herramientas de robótica a utilizar para poder enfrentar el desafío de la recolección masiva de arándanos en un entorno colaborativo, donde interacciona tanto navegación en exteriores (GNSS/GPS mas análisis de correcciones) ,  manipulación de precisión (bridge entre ROS y URScript) , y ROS.</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1800;">18:00</h3>

	<div class="session session-57 track-1" style="grid-column: track-1; grid-row: time-1800 / time-1815;">
		<span class="session-time">18:00 - 18:15</span>
		<span class="session-track">Paraninfo<br />Comunicaciones en ROS</span>
		<br />
		<h4 class="session-title">Evaluación de las comunicaciones ROS 2 para enjambres inalámbricos</h4>
		<h4 class="session-presenter">
				José Borja Castillo Sánchez (Universidad de Málaga)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493333" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>En esta ponencia se pretende ilustrar, de una forma simple, cómo el número de robots y los parámetros de calidad de servicio pueden comprometer la estabilidad y fiabilidad de la comunicación en un enjambre de robots inalámbricos. Para ello, se presentará un banco de pruebas y una herramienta (paquete ROS 2) que han sido desarrollados. El fin que persigue esta herramienta es plantear una metodología para poder evaluar las métricas de comunicación más habituales (latencia y porcentaje de pérdidas) bajo diferentes condiciones. En este aspecto, se subrayará el impacto de algunos parámetros relativos al middleware y del sistema en relación con las métricas a evaluar. En cuanto al público objetivo, abarca un amplio abanico de usuarios, aunque está especialmente ideada para aquellos que deseen trabajar con ROS 2 en entornos inalámbricos.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1805;">18:05</h3>

	<div class="session session-58 track-2" style="grid-column: track-2; grid-row: time-1805 / time-1815;">
		<span class="session-time">18:05 - 18:15</span>
		<span class="session-track">Sala de Grados, Ed. 7<br />Aplicaciones</span>
		<br />
		<h4 class="session-title">Sistemas robóticos con ROS para el desmontaje y recuperación de materiales en baterías EV</h4>
		<h4 class="session-presenter">
				Èric Domingo Roca (Eurecat)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492989" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Debido al auge de los vehículos eléctricos, cada vez es más necesario disponer de soluciones avanzadas para la gestión del fin de vida (EoL) de las baterías de EV y la recuperación de sus elementos. En esta presentación, se explica cómo los sistemas robóticos con ROS ayudan a automatizar fases del desmontaje de baterías de EV. Estos sistemas garantizan un desmontaje seguro y eficiente, y su capacidad para clasificar los componentes sin dañarlos promueve una gestión sostenible de las baterías. Las soluciones robóticas con ROS mejoran la flexibilidad y productividad, maximizando la valorización de los residuos y reduciendo el impacto ambiental.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1815;">18:15</h3>

	<div class="session session-59 track-1" style="grid-column: track-1; grid-row: time-1815 / time-1830;">
		<span class="session-time">18:15 - 18:30</span>
		<span class="session-track">Paraninfo<br />Comunicaciones en ROS</span>
		<br />
		<h4 class="session-title">Mejora de la escalabilidad y simplificación de la configuración de las comunicaciones en ROS 2</h4>
		<h4 class="session-presenter">
				Raúl Sánchez-Mateos Lizano (eProsima)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493484" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>En esta charla se van a presentar las últimas novedades y contribuciones de eProsima al ecosistema de ROS 2. Estas tienen como objetivo la mejora de la escalabilidad de los sistemas basados en ROS 2, la mejora de la eficiencia y comunicación entre nodos, y la propuesta de solucines por defecto o facilmente configurables para solventar los problemas de conectividad y redes más reportados por la comunidad de ROS (pérdida de datos, problemas de descubrimiento, problemas de conectividad en redes WiFi o congestionadas, etc.).</p>
<p>Para ello se presentarán con detalle los siguientes puntos, describiendo en cada uno de ellos las nuevas arquitecturas propuestas, y validando cada una mediante demostraciones en directo, con el fin de que el desarrollador de ROS 2 adquiera los punto clave de cada una de las nuevas funcionalidades disponibles y sepa aplicarlas a casos de uso reales de robótica.</p>
<p>1) Resolución de problemas de escalabilidad mediante el uso de ROS 2 Topic Keys: En los sistemas robóticos modernos, y más concretamente en los sistemas ROS 2, es imprescindible la gestión eficiente de los recursos. Los métodos tradicionales pueden provocar ineficiencias en el ancho de banda empleado en las comunicaciones, así como un mayor uso de los recursos del sistema, lo cual tiene un impacto en la escalabilidad y el rendimiento de estos. La nueva caráteristica de “Topic Keys” expuesta en ROS 2 pretende abordar estos retos exponiendo y haciendo utilizable esta potente funcionalidad de DDS en las capas de ROS 2. La presentación comenzará con una visión general de la motivación que subyace al uso de “Topic Keys”. En entornos robóticos complejos, múltiples flujos de datos a menudo necesitan compartir temas de comunicación. Los tópicos con clave (“keyed topics”) proporcionan un identificador único para cada flujo de datos dentro de un tópico de ROS 2, lo que permite que estos flujos coexistan de manera eficiente en un único tópico. Esto reduce el número de entidades necesarias, como publicadores y suscriptores, lo que conduce a un uso más eficiente de los recursos y el ancho de banda. Este punto también cubrirá un ejemplo práctico de cómo implementar tópicos con clave dentro de ROS 2. Mostraré varios casos de uso en sistemas robóticos, demostrando cómo los tópicos con clave puede ser aplicado para optimizar la comunicación en escenarios del mundo real. Los asistentes verán demostraciones en vivo cómo configurar estos tópicos, destacando la facilidad de uso y los beneficios tangibles en términos de rendimiento y escalabilidad.</p>
<p>2) En la siguiente sección se presentarán dos nuevos mecanismos para solucionar problemas de conectividad sin necesidad de tener ningún conocimiento sobre redes de communication. De esta forma el desarrollador de ROS 2 puede centrarse en resolver aquellos problemas relaccionados con su robot sin preocuparse sobre problemas de red y fallos en la conectividad de los nodos.</p>
<p>Aunque diversas técnicas como la compresión de datos o el ajuste de la capa DDS pueden mejorar el rendimiento de ROS 2 a nivel de aplicación, no es razonable esperar que los especialistas en robótica se conviertan en expertos en redes. Este cambio de enfoque les desviaría de su labor principal en el ámbito de las capacidades robóticas, lo que repercutiría negativamente en el conjunto de la comunidad de ROS 2.
Reconociendo este reto, eProsima ha desarrollado una opción de “configuración cero” para Fast DDS, diseñada específicamente para la comunicación de mensajes de gran tamaño de forma eficiente y fiable a través de redes con pérdidas (e.g. redes WiFi). Esta nueva configuración, denominada modo “Large Data”, intenta abordar estos problemas fundamentales a los que se enfrentan los usuarios de ROS 2. El modo “Large Data” resuelve este problema cambiando la comunicación de las aplicaciones ROS 2 a TCP, un protocolo diseñado para la transmisión fiable de datos. A pesar de la inherente naturaleza orientada a la conexión de TCP, el modo “Large Data” conserva el descubrimiento dinámico de nodos realizando la fase de descubrimiento multicast sobre UDP. Este enfoque híbrido combina las ventajas del descubrimiento dinámico con la entrega fiable de mensajes de gran tamaño, incluso en condiciones de red subóptimas; ¡todo ello alcanzable mediante una simple exportación de variables de entorno!.</p>
<p>El segundo problema que podrías  encontramos es la posible congestión de la red durante el proceso de descubrimiento. Para solucionarlo se presentará una nueva versión de Discovery Server completamente que permite el despliegue de redes ROS 2 sin utilizar ningún tipo de comunicación multicast y con una configuración mínima de los servidores. Es decir, se trata de un nuevo modelo semiautomático de descubrimiento y despliegue de servidores basado en Discovery Server y comunicación fiable punto a punto. La antigua configuración de este mecanismo de descubrimiento requería especificar el par IP-puerto de escucha y un ID fijo para cada servidor desplegado, lo que podía afectar negativamente a la flexibilidad y escalabilidad del sistema. Además, el uso de un ID único fijo era problemático para los despliegues dinámicos, en los que la introducción de nuevos servidores en las redes sólo era posible conociendo manualmente el GUID de otro servidor.  La nueva versión de Discovery Server permite a los desarrolladores de robótica poner en marcha fácilmente un servidor sin necesidad de configuración, es decir, no se requerirá ni el par IP-puerto ni el ID del servidor. Esto se aplica tanto al inicio del servidor como al lanzamiento del cliente.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1830;">18:30</h3>

	<div class="session session-60 track-all" style="grid-column: track-1-start / track-2-end; grid-row: time-1830 / time-1840;">
		<span class="session-time">18:30 - 18:40</span>
		<br />
		<h4 class="session-title">Shuffle</h4>
	</div>

	<h3 class="time-slot" style="grid-row: time-1840;">18:40</h3>

	<div class="session session-61 track-1" style="grid-column: track-1; grid-row: time-1840 / time-1855;">
		<span class="session-time">18:40 - 18:55</span>
		<span class="session-track">Paraninfo<br />Manipulación</span>
		<br />
		<h4 class="session-title">Trabajar fácilmente con la mano robótica Allegro Hand</h4>
		<h4 class="session-presenter">
				Leopold Palomo-Avellaneda (Instituto de Organización y Control de Sistemas Industriales - Universitat Politècnica de Catalunya)<br />
				Marina Pujol-Closa (Instituto de Organización y Control de Sistemas Industriales - Universitat Politècnica de Catalunya)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493757" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>El objetivo de este trabajo es el desarrollo de un paquete de software completo para explotar una mano antropomórfica robótica, como la mano robótica de Alegro, permitiendo realizar fácilmente aprehensiones precisas. Incluye la cinemática inversa y la cinemática directa. También permite almacenar diferentes configuraciones, así como realizar y almacenar agarres predefinidos mientras se controla la velocidad de movimiento.</p>
<p>El software presentado permite el fácil uso de la mano robótica de Alegro, mejorando sus capacidades y permitiendo mayor investigación sobre la teoría de la prensión, facilitando la implementación experimental. El software está diseñado para trabajar con todas las versiones de Allegro Hand a pesar de sus diferencias.</p>
<p>Es una alternativa mejorada en la versión del fabricante, ofreciendo un potente marco para la sujeción, con una capa ROS2 con toda la funcionalidad. Además, ha sido diseñado para adaptarse fácilmente a otras manos robóticas antropomórficas.</p>
		</details>
	</div>

	<div class="session session-62 track-2" style="grid-column: track-2; grid-row: time-1840 / time-1855;">
		<span class="session-time">18:40 - 18:55</span>
		<span class="session-track">Sala de Grados, Ed. 7</span>
		<br />
		<h4 class="session-title">Planifica hasta tus rutinas utilizando LLMs</h4>
		<h4 class="session-presenter">
				Alejandro González Cantón (Universidad de León)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492861" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>En esta charla se describirá la utilización de llama_ros (LLaMA.cpp en ROS 2) con modelos cuantizados y gramáticas GBNF para realizar planificación, mediante la generación de árboles de comportamiento. Además, se mostrará un caso de uso de su aplicación para la prueba de la RoboCup GPSR (General Porpose Service Robot).</p>
	</div>

	<h3 class="time-slot" style="grid-row: time-1855;">18:55</h3>

	<div class="session session-63 track-1" style="grid-column: track-1; grid-row: time-1855 / time-1910;">
		<span class="session-time">18:55 - 19:10</span>
		<span class="session-track">Paraninfo<br />Manipulación</span>
		<br />
		<h4 class="session-title">Un manipulador robótico de doble brazo con guiado visual: una experiencia de implementación en ROS 2</h4>
		<h4 class="session-presenter">
				Jan Rosell (Instituto de Organización y Control de Sistemas Industriales - Universitat Politècnica de Catalunya)<br />
				Pol Ramon-Canyemeres (Instituto de Organización y Control de Sistemas Industriales - Universitat Politècnica de Catalunya)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493777" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>La manipulación con robots bibrazo plantea muchos desafíos para poder realizar de manera eficiente tareas de manipulación. Para abordar estos desafíos, este trabajo describe un sistema de coordinación de movimientos de un robot antropomórfico bibrazo con base móvil, centrado en desarrollar la capacidad de realizar acciones coordinadas de manipulación con precisión, usando la ayuda de una guiado visual proporcionado por una cámara montada en una cabeza articulada. La charla presentará diferentes modos de control evaluados con experimentos reales.</p>
	</div>

	<div class="session session-64 track-2" style="grid-column: track-2; grid-row: time-1855 / time-1910;">
		<span class="session-time">18:55 - 19:10</span>
		<span class="session-track">Sala de Grados, Ed. 7</span>
		<br />
		<h4 class="session-title">Desplegando Algoritmos de Visión Artificial en Dispositivos Embebidos con ROS 2</h4>
		<h4 class="session-presenter">
				Santiago Montiel Marín (Universidad de Alcalá)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029492491" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>Los métodos de visión artificial basado en aprendizaje profundo juegan un rol fundamental en los sistemas de percepción de las arquitecturas de software para robots. Obtener, interpretar y elaborar la información procedente de los sensores (como las cámaras) es una tarea que debe realizarse con la mayor celeridad posible para que la navegación autónoma y la actuación se puedan llevar a cabo con éxito.</p>
<p>En esta charla, exploraremos un caso de uso en el que tomando como base un modelo de visión artificial, se analizarán y discutirán estrategias sobre como integrarlos eficientemente en hardware de recursos limitados ampliamente usados en al ámbito de la robótica, como las tarjetas NVIDIA Jetson. Se explorarán métodos como la cuantización y el pruning, así como una serie de buenas prácticas en el contexto de ROS2, y se aportarán comparativas que puedan guiar los futuros despliegues de algoritmos de visión en la comunidad.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1910;">19:10</h3>

	<div class="session session-65 track-1" style="grid-column: track-1; grid-row: time-1910 / time-1925;">
		<span class="session-time">19:10 - 19:25</span>
		<span class="session-track">Paraninfo<br />Manipulación</span>
		<br />
		<h4 class="session-title">Integración de Allegro Hand en ROS 2</h4>
		<h4 class="session-presenter">
				Aina Irisarri Carrió (PAL Robotics)
		</h4>
		<a href="https://vimeo.com/showcase/11453818/video/1029493420" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
<p>En esta charla explicaremos los pasos esenciales para configurar y ejecutar una simulación funcional de la mano robótica Allegro Hand en ROS 2. Partiendo desde la creación del paquete de descripción con URDF, cubriremos cómo utilizar herramientas como Gazebo y RViz2 para visualizar la simulación.</p>
	</div>

	<div class="session session-66 track-2" style="grid-column: track-2; grid-row: time-1910 / time-1925;">
		<span class="session-time">19:10 - 19:25</span>
		<span class="session-track">Sala de Grados, Ed. 7</span>
		<br />
		<h4 class="session-title">PILOTING Robot Control Station</h4>
		<h4 class="session-presenter">
				José Manuel González Marín (CATEC - Centro Avanzado de Tecnologías Aeroespaciales)
		</h4>
		<a href="https://github.com/catec/piloting_grcs" target="_blank" style="color:white" class="video-link">🤖 Ver código</a><br />
		<a href="https://vimeo.com/showcase/11453818/video/1029492843" target="_blank" style="color:white" class="video-link">🎞 Vídeo</a><br />
		<br />
		<details class="session-description">
		<summary>Ver descripción</summary>
<p>PILOTING es un proyecto europeo del programa H2020 que validó la adaptación, integración y demostración de soluciones robóticas mediante una plataforma integrada en tres pilotos a gran escala: refinerías, viaductos y túneles, con la implicación de todos los actores que conforman la cadena de valor completa. La plataforma PILOTING es un sistema integrado y unificado de componentes de hardware y software para aumentar la eficiencia y la calidad de las actividades de inspección y mantenimiento, con el fin de mantener los niveles de seguridad necesarios en infraestructura civil. Dentro de esta plataforma, desde CATEC hemos desarrollado una estación de control (Robot Control Station) para homogeneizar la operación de distintas soluciones robóticas, tanto terrestres como aéreas, en cuanto a las misiones autónomas de inspección y mantenimiento.</p>
		</details>
	</div>

	<h3 class="time-slot" style="grid-row: time-1930;">19:30</h3>

	<div class="session session-67 track-all" style="grid-column: track-1-start / track-2-end; grid-row: time-1930 / time-2000;">
		<span class="session-time">19:30 - 20:00</span>
		<span class="session-track">Paraninfo</span>
		<br />
		<h4 class="session-title">Clausura</h4>
	</div>

	<h3 class="time-slot" style="grid-row: time-2000;">20:00</h3>

	<div class="session session-68 track-all" style="grid-column: track-1-start / track-2-end; grid-row: time-2000 / time-2200;">
		<span class="session-time">20:00 - 22:00</span>
		<span class="session-track">Paraninfo</span>
		<br />
		<h4 class="session-title">Cocktail Party</h4>
	</div>

</div>
